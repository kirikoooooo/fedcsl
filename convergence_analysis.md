# 客户端选择概率收敛性分析

## 1. 指数移动平均（EMA）的数学收敛性

### 1.1 EMA更新公式
```
p^(t+1) = α * target^(t) + (1-α) * p^(t)
```

其中：
- `p^(t)` 是第 t 轮的概率向量
- `target^(t)` 是基于OMP贡献计算的目标概率
- `α = ema_alpha` 是平滑系数（默认0.3）

### 1.2 收敛性证明

展开EMA公式：
```
p^(t+1) = α * target^(t) + (1-α) * p^(t)
        = α * target^(t) + (1-α) * [α * target^(t-1) + (1-α) * p^(t-1)]
        = α * target^(t) + α(1-α) * target^(t-1) + (1-α)² * p^(t-1)
        = ...
        = α * Σ[(1-α)^k * target^(t-k)] + (1-α)^(t+1) * p^(0)
```

当 t → ∞ 时：
- 如果 `target^(t)` 收敛到固定值 `target*`，则 `p^(t)` 收敛到 `target*`
- 权重系数：`α * Σ[(1-α)^k] = α * 1/(1-(1-α)) = 1`（几何级数求和）

### 1.3 收敛速度

收敛速度由 `(1-α)` 决定：
- `α = 0.3` 时，每轮保留 70% 的旧值，30% 的新值
- 收敛到稳定值的轮数约为 `-log(ε) / log(1-α)`，其中 ε 是精度要求
- 例如：要达到 1% 精度，约需 `-log(0.01) / log(0.7) ≈ 12.8` 轮

## 2. 固定点理论（Fixed Point Theory）

### 2.1 更新映射的固定点

定义更新函数 `T: P → P`，其中 P 是概率单纯形（所有概率向量之和为1）：
```
T(p) = normalize(max(α * target(p) + (1-α) * p, min_prob))
```

### 2.2 固定点存在性

根据 **Brouwer不动点定理**：
- 概率单纯形是紧致凸集
- 更新函数 T 是连续的（因为所有操作都是连续的）
- 因此存在固定点 `p*` 使得 `T(p*) = p*`

### 2.3 固定点稳定性

当 `target(p)` 稳定时（即OMP贡献分布稳定），EMA更新会收敛到该固定点。

## 3. 有界性和稳定性保证

### 3.1 最小概率保护

```python
updated_probs = np.maximum(updated_probs, min_selection_prob)
```

这确保了：
- 所有概率有下界：`p_i ≥ min_prob > 0`
- 避免概率完全为0导致的采样失败
- 保证所有客户端都有被选中的机会

### 3.2 归一化保证

```python
updated_probs = updated_probs / updated_probs.sum()
```

这确保了：
- 概率总和始终为1：`Σ p_i = 1`
- 概率向量始终在概率单纯形内
- 更新过程不会"逃逸"出有效概率空间

## 4. 目标概率的稳定性

### 4.1 目标概率计算

```python
contribution_ratio = x_processed[i] / total_contribution
target_probs[i] = contribution_ratio * prob_share
```

### 4.2 稳定性来源

- **OMP稀疏向量的稳定性**：随着训练进行，模型参数变化减小，OMP重构的稀疏向量趋于稳定
- **贡献比例的归一化**：`contribution_ratio` 是归一化的（总和为1），天然稳定
- **概率份额的连续性**：`prob_share` 是上一轮概率的连续函数

## 5. 收敛的充分条件

### 5.1 条件1：目标概率收敛

如果 `target^(t)` 收敛到 `target*`，则：
```
lim(t→∞) ||target^(t) - target*|| = 0
```

### 5.2 条件2：EMA权重和

EMA的权重系数满足：
```
α * Σ[(1-α)^k] = 1  (k从0到∞)
```

### 5.3 结论

当两个条件都满足时：
```
lim(t→∞) ||p^(t) - target*|| = 0
```

## 6. 实际收敛行为

### 6.1 初期阶段（快速调整）
- 模型参数变化大，OMP贡献变化明显
- EMA快速响应，概率快速调整
- 高贡献客户端概率上升，低贡献客户端概率下降

### 6.2 中期阶段（平滑过渡）
- 模型参数变化减小
- EMA平滑作用明显，概率变化减缓
- 概率分布逐步稳定

### 6.3 后期阶段（收敛稳定）
- 模型接近收敛，OMP贡献稳定
- 目标概率趋于固定
- EMA使概率收敛到稳定分布

## 7. 数学证明概要

### 7.1 更新算子的收缩性

考虑概率空间上的距离度量（如L1距离）：
```
d(p^(t+1), p^*) = ||α * target^(t) + (1-α) * p^(t) - p*||
                ≤ α * ||target^(t) - target*|| + (1-α) * ||p^(t) - p*||
```

当 `target^(t)` 接近 `target*` 时，上式右侧趋于 `(1-α) * ||p^(t) - p*||`。

由于 `(1-α) < 1`，更新算子是收缩的，保证收敛。

### 7.2 收敛速率

收敛速率：
```
||p^(t) - p*|| ≤ (1-α)^t * ||p^(0) - p*|| + α * Σ[(1-α)^k * ||target^(t-k) - target*||]
```

当 `target^(t)` 稳定时，第二项趋于0，收敛速率主要由 `(1-α)^t` 决定。

## 8. 总结

概率收敛的保证来自：

1. **EMA的数学性质**：指数加权平均天然具有平滑和收敛特性
2. **固定点存在性**：Brouwer定理保证固定点存在
3. **有界性保护**：最小概率和归一化确保概率在有效空间内
4. **目标稳定性**：OMP贡献随训练稳定而稳定
5. **收缩性**：更新算子在稳定状态下是收缩的

这些机制共同作用，确保概率向量能够收敛到稳定的分布。

