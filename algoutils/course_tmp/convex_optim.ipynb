{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/938], Loss: 1.0755\n",
      "Epoch [1/100], Step [200/938], Loss: 0.6967\n",
      "Epoch [1/100], Step [300/938], Loss: 0.4040\n",
      "Epoch [1/100], Step [400/938], Loss: 0.5804\n",
      "Epoch [1/100], Step [500/938], Loss: 0.5115\n",
      "Epoch [1/100], Step [600/938], Loss: 0.4459\n",
      "Epoch [1/100], Step [700/938], Loss: 0.3438\n",
      "Epoch [1/100], Step [800/938], Loss: 0.2511\n",
      "Epoch [1/100], Step [900/938], Loss: 0.2335\n",
      "Test Accuracy: 90.82%\n",
      "Epoch [2/100], Step [100/938], Loss: 0.2681\n",
      "Epoch [2/100], Step [200/938], Loss: 0.2922\n",
      "Epoch [2/100], Step [300/938], Loss: 0.5008\n",
      "Epoch [2/100], Step [400/938], Loss: 0.2217\n",
      "Epoch [2/100], Step [500/938], Loss: 0.2483\n",
      "Epoch [2/100], Step [600/938], Loss: 0.1677\n",
      "Epoch [2/100], Step [700/938], Loss: 0.3370\n",
      "Epoch [2/100], Step [800/938], Loss: 0.3389\n",
      "Epoch [2/100], Step [900/938], Loss: 0.1989\n",
      "Test Accuracy: 92.69%\n",
      "Epoch [3/100], Step [100/938], Loss: 0.2270\n",
      "Epoch [3/100], Step [200/938], Loss: 0.2666\n",
      "Epoch [3/100], Step [300/938], Loss: 0.1596\n",
      "Epoch [3/100], Step [400/938], Loss: 0.1878\n",
      "Epoch [3/100], Step [500/938], Loss: 0.2512\n",
      "Epoch [3/100], Step [600/938], Loss: 0.2775\n",
      "Epoch [3/100], Step [700/938], Loss: 0.2067\n",
      "Epoch [3/100], Step [800/938], Loss: 0.2268\n",
      "Epoch [3/100], Step [900/938], Loss: 0.1993\n",
      "Test Accuracy: 93.42%\n",
      "Epoch [4/100], Step [100/938], Loss: 0.1597\n",
      "Epoch [4/100], Step [200/938], Loss: 0.1800\n",
      "Epoch [4/100], Step [300/938], Loss: 0.1266\n",
      "Epoch [4/100], Step [400/938], Loss: 0.3085\n",
      "Epoch [4/100], Step [500/938], Loss: 0.1432\n",
      "Epoch [4/100], Step [600/938], Loss: 0.1856\n",
      "Epoch [4/100], Step [700/938], Loss: 0.1355\n",
      "Epoch [4/100], Step [800/938], Loss: 0.3111\n",
      "Epoch [4/100], Step [900/938], Loss: 0.2016\n",
      "Test Accuracy: 94.10%\n",
      "Epoch [5/100], Step [100/938], Loss: 0.2726\n",
      "Epoch [5/100], Step [200/938], Loss: 0.2280\n",
      "Epoch [5/100], Step [300/938], Loss: 0.5133\n",
      "Epoch [5/100], Step [400/938], Loss: 0.1288\n",
      "Epoch [5/100], Step [500/938], Loss: 0.3532\n",
      "Epoch [5/100], Step [600/938], Loss: 0.1396\n",
      "Epoch [5/100], Step [700/938], Loss: 0.2091\n",
      "Epoch [5/100], Step [800/938], Loss: 0.1230\n",
      "Epoch [5/100], Step [900/938], Loss: 0.0867\n",
      "Test Accuracy: 94.63%\n",
      "Epoch [6/100], Step [100/938], Loss: 0.1812\n",
      "Epoch [6/100], Step [200/938], Loss: 0.1946\n",
      "Epoch [6/100], Step [300/938], Loss: 0.1143\n",
      "Epoch [6/100], Step [400/938], Loss: 0.1371\n",
      "Epoch [6/100], Step [500/938], Loss: 0.1378\n",
      "Epoch [6/100], Step [600/938], Loss: 0.1221\n",
      "Epoch [6/100], Step [700/938], Loss: 0.2487\n",
      "Epoch [6/100], Step [800/938], Loss: 0.1130\n",
      "Epoch [6/100], Step [900/938], Loss: 0.0523\n",
      "Test Accuracy: 95.04%\n",
      "Epoch [7/100], Step [100/938], Loss: 0.1314\n",
      "Epoch [7/100], Step [200/938], Loss: 0.2596\n",
      "Epoch [7/100], Step [300/938], Loss: 0.2438\n",
      "Epoch [7/100], Step [400/938], Loss: 0.1668\n",
      "Epoch [7/100], Step [500/938], Loss: 0.1296\n",
      "Epoch [7/100], Step [600/938], Loss: 0.1147\n",
      "Epoch [7/100], Step [700/938], Loss: 0.1095\n",
      "Epoch [7/100], Step [800/938], Loss: 0.0269\n",
      "Epoch [7/100], Step [900/938], Loss: 0.1178\n",
      "Test Accuracy: 95.57%\n",
      "Epoch [8/100], Step [100/938], Loss: 0.0528\n",
      "Epoch [8/100], Step [200/938], Loss: 0.1856\n",
      "Epoch [8/100], Step [300/938], Loss: 0.0955\n",
      "Epoch [8/100], Step [400/938], Loss: 0.2073\n",
      "Epoch [8/100], Step [500/938], Loss: 0.2131\n",
      "Epoch [8/100], Step [600/938], Loss: 0.1804\n",
      "Epoch [8/100], Step [700/938], Loss: 0.1198\n",
      "Epoch [8/100], Step [800/938], Loss: 0.1431\n",
      "Epoch [8/100], Step [900/938], Loss: 0.0750\n",
      "Test Accuracy: 95.78%\n",
      "Epoch [9/100], Step [100/938], Loss: 0.1246\n",
      "Epoch [9/100], Step [200/938], Loss: 0.2580\n",
      "Epoch [9/100], Step [300/938], Loss: 0.0701\n",
      "Epoch [9/100], Step [400/938], Loss: 0.1251\n",
      "Epoch [9/100], Step [500/938], Loss: 0.0927\n",
      "Epoch [9/100], Step [600/938], Loss: 0.0845\n",
      "Epoch [9/100], Step [700/938], Loss: 0.1629\n",
      "Epoch [9/100], Step [800/938], Loss: 0.1666\n",
      "Epoch [9/100], Step [900/938], Loss: 0.1051\n",
      "Test Accuracy: 96.09%\n",
      "Epoch [10/100], Step [100/938], Loss: 0.1192\n",
      "Epoch [10/100], Step [200/938], Loss: 0.1225\n",
      "Epoch [10/100], Step [300/938], Loss: 0.1759\n",
      "Epoch [10/100], Step [400/938], Loss: 0.0981\n",
      "Epoch [10/100], Step [500/938], Loss: 0.0511\n",
      "Epoch [10/100], Step [600/938], Loss: 0.0445\n",
      "Epoch [10/100], Step [700/938], Loss: 0.1427\n",
      "Epoch [10/100], Step [800/938], Loss: 0.1738\n",
      "Epoch [10/100], Step [900/938], Loss: 0.0543\n",
      "Test Accuracy: 96.26%\n",
      "Epoch [11/100], Step [100/938], Loss: 0.1441\n",
      "Epoch [11/100], Step [200/938], Loss: 0.0882\n",
      "Epoch [11/100], Step [300/938], Loss: 0.2970\n",
      "Epoch [11/100], Step [400/938], Loss: 0.3614\n",
      "Epoch [11/100], Step [500/938], Loss: 0.0938\n",
      "Epoch [11/100], Step [600/938], Loss: 0.0901\n",
      "Epoch [11/100], Step [700/938], Loss: 0.2501\n",
      "Epoch [11/100], Step [800/938], Loss: 0.0431\n",
      "Epoch [11/100], Step [900/938], Loss: 0.1400\n",
      "Test Accuracy: 96.52%\n",
      "Epoch [12/100], Step [100/938], Loss: 0.1089\n",
      "Epoch [12/100], Step [200/938], Loss: 0.0644\n",
      "Epoch [12/100], Step [300/938], Loss: 0.1702\n",
      "Epoch [12/100], Step [400/938], Loss: 0.1818\n",
      "Epoch [12/100], Step [500/938], Loss: 0.0609\n",
      "Epoch [12/100], Step [600/938], Loss: 0.0586\n",
      "Epoch [12/100], Step [700/938], Loss: 0.1226\n",
      "Epoch [12/100], Step [800/938], Loss: 0.1286\n",
      "Epoch [12/100], Step [900/938], Loss: 0.0843\n",
      "Test Accuracy: 96.65%\n",
      "Epoch [13/100], Step [100/938], Loss: 0.0962\n",
      "Epoch [13/100], Step [200/938], Loss: 0.0730\n",
      "Epoch [13/100], Step [300/938], Loss: 0.0743\n",
      "Epoch [13/100], Step [400/938], Loss: 0.1864\n",
      "Epoch [13/100], Step [500/938], Loss: 0.0392\n",
      "Epoch [13/100], Step [600/938], Loss: 0.1348\n",
      "Epoch [13/100], Step [700/938], Loss: 0.1231\n",
      "Epoch [13/100], Step [800/938], Loss: 0.0344\n",
      "Epoch [13/100], Step [900/938], Loss: 0.0542\n",
      "Test Accuracy: 96.86%\n",
      "Epoch [14/100], Step [100/938], Loss: 0.0887\n",
      "Epoch [14/100], Step [200/938], Loss: 0.1031\n",
      "Epoch [14/100], Step [300/938], Loss: 0.2770\n",
      "Epoch [14/100], Step [400/938], Loss: 0.0358\n",
      "Epoch [14/100], Step [500/938], Loss: 0.1313\n",
      "Epoch [14/100], Step [600/938], Loss: 0.0543\n",
      "Epoch [14/100], Step [700/938], Loss: 0.0992\n",
      "Epoch [14/100], Step [800/938], Loss: 0.0840\n",
      "Epoch [14/100], Step [900/938], Loss: 0.0406\n",
      "Test Accuracy: 96.87%\n",
      "Epoch [15/100], Step [100/938], Loss: 0.0210\n",
      "Epoch [15/100], Step [200/938], Loss: 0.2593\n",
      "Epoch [15/100], Step [300/938], Loss: 0.0460\n",
      "Epoch [15/100], Step [400/938], Loss: 0.0702\n",
      "Epoch [15/100], Step [500/938], Loss: 0.0407\n",
      "Epoch [15/100], Step [600/938], Loss: 0.1597\n",
      "Epoch [15/100], Step [700/938], Loss: 0.1327\n",
      "Epoch [15/100], Step [800/938], Loss: 0.1408\n",
      "Epoch [15/100], Step [900/938], Loss: 0.0790\n",
      "Test Accuracy: 97.07%\n",
      "Epoch [16/100], Step [100/938], Loss: 0.0392\n",
      "Epoch [16/100], Step [200/938], Loss: 0.1378\n",
      "Epoch [16/100], Step [300/938], Loss: 0.0423\n",
      "Epoch [16/100], Step [400/938], Loss: 0.0535\n",
      "Epoch [16/100], Step [500/938], Loss: 0.0849\n",
      "Epoch [16/100], Step [600/938], Loss: 0.0498\n",
      "Epoch [16/100], Step [700/938], Loss: 0.1493\n",
      "Epoch [16/100], Step [800/938], Loss: 0.1899\n",
      "Epoch [16/100], Step [900/938], Loss: 0.1116\n",
      "Test Accuracy: 97.17%\n",
      "Epoch [17/100], Step [100/938], Loss: 0.1097\n",
      "Epoch [17/100], Step [200/938], Loss: 0.0383\n",
      "Epoch [17/100], Step [300/938], Loss: 0.0620\n",
      "Epoch [17/100], Step [400/938], Loss: 0.0596\n",
      "Epoch [17/100], Step [500/938], Loss: 0.0665\n",
      "Epoch [17/100], Step [600/938], Loss: 0.0788\n",
      "Epoch [17/100], Step [700/938], Loss: 0.0833\n",
      "Epoch [17/100], Step [800/938], Loss: 0.0534\n",
      "Epoch [17/100], Step [900/938], Loss: 0.1437\n",
      "Test Accuracy: 97.15%\n",
      "Epoch [18/100], Step [100/938], Loss: 0.0640\n",
      "Epoch [18/100], Step [200/938], Loss: 0.0532\n",
      "Epoch [18/100], Step [300/938], Loss: 0.0515\n",
      "Epoch [18/100], Step [400/938], Loss: 0.0394\n",
      "Epoch [18/100], Step [500/938], Loss: 0.1743\n",
      "Epoch [18/100], Step [600/938], Loss: 0.2325\n",
      "Epoch [18/100], Step [700/938], Loss: 0.0450\n",
      "Epoch [18/100], Step [800/938], Loss: 0.0509\n",
      "Epoch [18/100], Step [900/938], Loss: 0.1061\n",
      "Test Accuracy: 97.34%\n",
      "Epoch [19/100], Step [100/938], Loss: 0.0530\n",
      "Epoch [19/100], Step [200/938], Loss: 0.0907\n",
      "Epoch [19/100], Step [300/938], Loss: 0.0241\n",
      "Epoch [19/100], Step [400/938], Loss: 0.0287\n",
      "Epoch [19/100], Step [500/938], Loss: 0.1110\n",
      "Epoch [19/100], Step [600/938], Loss: 0.2258\n",
      "Epoch [19/100], Step [700/938], Loss: 0.1274\n",
      "Epoch [19/100], Step [800/938], Loss: 0.0840\n",
      "Epoch [19/100], Step [900/938], Loss: 0.1293\n",
      "Test Accuracy: 97.30%\n",
      "Epoch [20/100], Step [100/938], Loss: 0.0303\n",
      "Epoch [20/100], Step [200/938], Loss: 0.0303\n",
      "Epoch [20/100], Step [300/938], Loss: 0.1705\n",
      "Epoch [20/100], Step [400/938], Loss: 0.0388\n",
      "Epoch [20/100], Step [500/938], Loss: 0.0339\n",
      "Epoch [20/100], Step [600/938], Loss: 0.0574\n",
      "Epoch [20/100], Step [700/938], Loss: 0.0756\n",
      "Epoch [20/100], Step [800/938], Loss: 0.1065\n",
      "Epoch [20/100], Step [900/938], Loss: 0.0507\n",
      "Test Accuracy: 97.30%\n",
      "Epoch [21/100], Step [100/938], Loss: 0.0309\n",
      "Epoch [21/100], Step [200/938], Loss: 0.0183\n",
      "Epoch [21/100], Step [300/938], Loss: 0.0548\n",
      "Epoch [21/100], Step [400/938], Loss: 0.0285\n",
      "Epoch [21/100], Step [500/938], Loss: 0.0621\n",
      "Epoch [21/100], Step [600/938], Loss: 0.0778\n",
      "Epoch [21/100], Step [700/938], Loss: 0.0651\n",
      "Epoch [21/100], Step [800/938], Loss: 0.0588\n",
      "Epoch [21/100], Step [900/938], Loss: 0.0329\n",
      "Test Accuracy: 97.46%\n",
      "Epoch [22/100], Step [100/938], Loss: 0.0657\n",
      "Epoch [22/100], Step [200/938], Loss: 0.1172\n",
      "Epoch [22/100], Step [300/938], Loss: 0.0267\n",
      "Epoch [22/100], Step [400/938], Loss: 0.0341\n",
      "Epoch [22/100], Step [500/938], Loss: 0.0756\n",
      "Epoch [22/100], Step [600/938], Loss: 0.0607\n",
      "Epoch [22/100], Step [700/938], Loss: 0.0416\n",
      "Epoch [22/100], Step [800/938], Loss: 0.0363\n",
      "Epoch [22/100], Step [900/938], Loss: 0.0683\n",
      "Test Accuracy: 97.41%\n",
      "Epoch [23/100], Step [100/938], Loss: 0.0168\n",
      "Epoch [23/100], Step [200/938], Loss: 0.0586\n",
      "Epoch [23/100], Step [300/938], Loss: 0.0160\n",
      "Epoch [23/100], Step [400/938], Loss: 0.0372\n",
      "Epoch [23/100], Step [500/938], Loss: 0.0660\n",
      "Epoch [23/100], Step [600/938], Loss: 0.0992\n",
      "Epoch [23/100], Step [700/938], Loss: 0.0227\n",
      "Epoch [23/100], Step [800/938], Loss: 0.0767\n",
      "Epoch [23/100], Step [900/938], Loss: 0.0379\n",
      "Test Accuracy: 97.47%\n",
      "Epoch [24/100], Step [100/938], Loss: 0.0652\n",
      "Epoch [24/100], Step [200/938], Loss: 0.1293\n",
      "Epoch [24/100], Step [300/938], Loss: 0.0145\n",
      "Epoch [24/100], Step [400/938], Loss: 0.0465\n",
      "Epoch [24/100], Step [500/938], Loss: 0.0907\n",
      "Epoch [24/100], Step [600/938], Loss: 0.0067\n",
      "Epoch [24/100], Step [700/938], Loss: 0.1941\n",
      "Epoch [24/100], Step [800/938], Loss: 0.0171\n",
      "Epoch [24/100], Step [900/938], Loss: 0.0333\n",
      "Test Accuracy: 97.54%\n",
      "Epoch [25/100], Step [100/938], Loss: 0.0862\n",
      "Epoch [25/100], Step [200/938], Loss: 0.0386\n",
      "Epoch [25/100], Step [300/938], Loss: 0.0331\n",
      "Epoch [25/100], Step [400/938], Loss: 0.0230\n",
      "Epoch [25/100], Step [500/938], Loss: 0.0397\n",
      "Epoch [25/100], Step [600/938], Loss: 0.0861\n",
      "Epoch [25/100], Step [700/938], Loss: 0.0375\n",
      "Epoch [25/100], Step [800/938], Loss: 0.0332\n",
      "Epoch [25/100], Step [900/938], Loss: 0.0261\n",
      "Test Accuracy: 97.59%\n",
      "Epoch [26/100], Step [100/938], Loss: 0.0856\n",
      "Epoch [26/100], Step [200/938], Loss: 0.0477\n",
      "Epoch [26/100], Step [300/938], Loss: 0.0304\n",
      "Epoch [26/100], Step [400/938], Loss: 0.0965\n",
      "Epoch [26/100], Step [500/938], Loss: 0.0212\n",
      "Epoch [26/100], Step [600/938], Loss: 0.0734\n",
      "Epoch [26/100], Step [700/938], Loss: 0.0540\n",
      "Epoch [26/100], Step [800/938], Loss: 0.0381\n",
      "Epoch [26/100], Step [900/938], Loss: 0.0343\n",
      "Test Accuracy: 97.60%\n",
      "Epoch [27/100], Step [100/938], Loss: 0.0152\n",
      "Epoch [27/100], Step [200/938], Loss: 0.0572\n",
      "Epoch [27/100], Step [300/938], Loss: 0.0784\n",
      "Epoch [27/100], Step [400/938], Loss: 0.0598\n",
      "Epoch [27/100], Step [500/938], Loss: 0.1159\n",
      "Epoch [27/100], Step [600/938], Loss: 0.0500\n",
      "Epoch [27/100], Step [700/938], Loss: 0.1049\n",
      "Epoch [27/100], Step [800/938], Loss: 0.0678\n",
      "Epoch [27/100], Step [900/938], Loss: 0.0546\n",
      "Test Accuracy: 97.62%\n",
      "Epoch [28/100], Step [100/938], Loss: 0.0722\n",
      "Epoch [28/100], Step [200/938], Loss: 0.1280\n",
      "Epoch [28/100], Step [300/938], Loss: 0.0443\n",
      "Epoch [28/100], Step [400/938], Loss: 0.0348\n",
      "Epoch [28/100], Step [500/938], Loss: 0.0157\n",
      "Epoch [28/100], Step [600/938], Loss: 0.1433\n",
      "Epoch [28/100], Step [700/938], Loss: 0.0409\n",
      "Epoch [28/100], Step [800/938], Loss: 0.0268\n",
      "Epoch [28/100], Step [900/938], Loss: 0.0207\n",
      "Test Accuracy: 97.74%\n",
      "Epoch [29/100], Step [100/938], Loss: 0.0448\n",
      "Epoch [29/100], Step [200/938], Loss: 0.0574\n",
      "Epoch [29/100], Step [300/938], Loss: 0.0165\n",
      "Epoch [29/100], Step [400/938], Loss: 0.0077\n",
      "Epoch [29/100], Step [500/938], Loss: 0.0288\n",
      "Epoch [29/100], Step [600/938], Loss: 0.0477\n",
      "Epoch [29/100], Step [700/938], Loss: 0.0268\n",
      "Epoch [29/100], Step [800/938], Loss: 0.0178\n",
      "Epoch [29/100], Step [900/938], Loss: 0.0659\n",
      "Test Accuracy: 97.66%\n",
      "Epoch [30/100], Step [100/938], Loss: 0.0304\n",
      "Epoch [30/100], Step [200/938], Loss: 0.0646\n",
      "Epoch [30/100], Step [300/938], Loss: 0.0047\n",
      "Epoch [30/100], Step [400/938], Loss: 0.0838\n",
      "Epoch [30/100], Step [500/938], Loss: 0.0397\n",
      "Epoch [30/100], Step [600/938], Loss: 0.0808\n",
      "Epoch [30/100], Step [700/938], Loss: 0.0438\n",
      "Epoch [30/100], Step [800/938], Loss: 0.0443\n",
      "Epoch [30/100], Step [900/938], Loss: 0.0267\n",
      "Test Accuracy: 97.63%\n",
      "Epoch [31/100], Step [100/938], Loss: 0.0249\n",
      "Epoch [31/100], Step [200/938], Loss: 0.0464\n",
      "Epoch [31/100], Step [300/938], Loss: 0.0158\n",
      "Epoch [31/100], Step [400/938], Loss: 0.0473\n",
      "Epoch [31/100], Step [500/938], Loss: 0.0375\n",
      "Epoch [31/100], Step [600/938], Loss: 0.0121\n",
      "Epoch [31/100], Step [700/938], Loss: 0.0291\n",
      "Epoch [31/100], Step [800/938], Loss: 0.0350\n",
      "Epoch [31/100], Step [900/938], Loss: 0.0806\n",
      "Test Accuracy: 97.66%\n",
      "Epoch [32/100], Step [100/938], Loss: 0.0850\n",
      "Epoch [32/100], Step [200/938], Loss: 0.0444\n",
      "Epoch [32/100], Step [300/938], Loss: 0.1015\n",
      "Epoch [32/100], Step [400/938], Loss: 0.0249\n",
      "Epoch [32/100], Step [500/938], Loss: 0.0123\n",
      "Epoch [32/100], Step [600/938], Loss: 0.0444\n",
      "Epoch [32/100], Step [700/938], Loss: 0.0279\n",
      "Epoch [32/100], Step [800/938], Loss: 0.0477\n",
      "Epoch [32/100], Step [900/938], Loss: 0.0406\n",
      "Test Accuracy: 97.78%\n",
      "Epoch [33/100], Step [100/938], Loss: 0.0228\n",
      "Epoch [33/100], Step [200/938], Loss: 0.0350\n",
      "Epoch [33/100], Step [300/938], Loss: 0.0305\n",
      "Epoch [33/100], Step [400/938], Loss: 0.0363\n",
      "Epoch [33/100], Step [500/938], Loss: 0.0352\n",
      "Epoch [33/100], Step [600/938], Loss: 0.0456\n",
      "Epoch [33/100], Step [700/938], Loss: 0.0598\n",
      "Epoch [33/100], Step [800/938], Loss: 0.0755\n",
      "Epoch [33/100], Step [900/938], Loss: 0.0692\n",
      "Test Accuracy: 97.79%\n",
      "Epoch [34/100], Step [100/938], Loss: 0.0142\n",
      "Epoch [34/100], Step [200/938], Loss: 0.0328\n",
      "Epoch [34/100], Step [300/938], Loss: 0.0551\n",
      "Epoch [34/100], Step [400/938], Loss: 0.0408\n",
      "Epoch [34/100], Step [500/938], Loss: 0.0154\n",
      "Epoch [34/100], Step [600/938], Loss: 0.0244\n",
      "Epoch [34/100], Step [700/938], Loss: 0.0383\n",
      "Epoch [34/100], Step [800/938], Loss: 0.0629\n",
      "Epoch [34/100], Step [900/938], Loss: 0.1708\n",
      "Test Accuracy: 97.79%\n",
      "Epoch [35/100], Step [100/938], Loss: 0.0495\n",
      "Epoch [35/100], Step [200/938], Loss: 0.0376\n",
      "Epoch [35/100], Step [300/938], Loss: 0.0832\n",
      "Epoch [35/100], Step [400/938], Loss: 0.0176\n",
      "Epoch [35/100], Step [500/938], Loss: 0.0553\n",
      "Epoch [35/100], Step [600/938], Loss: 0.0332\n",
      "Epoch [35/100], Step [700/938], Loss: 0.0352\n",
      "Epoch [35/100], Step [800/938], Loss: 0.0300\n",
      "Epoch [35/100], Step [900/938], Loss: 0.0134\n",
      "Test Accuracy: 97.84%\n",
      "Epoch [36/100], Step [100/938], Loss: 0.0194\n",
      "Epoch [36/100], Step [200/938], Loss: 0.1255\n",
      "Epoch [36/100], Step [300/938], Loss: 0.0628\n",
      "Epoch [36/100], Step [400/938], Loss: 0.0331\n",
      "Epoch [36/100], Step [500/938], Loss: 0.0503\n",
      "Epoch [36/100], Step [600/938], Loss: 0.0157\n",
      "Epoch [36/100], Step [700/938], Loss: 0.0455\n",
      "Epoch [36/100], Step [800/938], Loss: 0.0299\n",
      "Epoch [36/100], Step [900/938], Loss: 0.0250\n",
      "Test Accuracy: 97.87%\n",
      "Epoch [37/100], Step [100/938], Loss: 0.0141\n",
      "Epoch [37/100], Step [200/938], Loss: 0.0088\n",
      "Epoch [37/100], Step [300/938], Loss: 0.0202\n",
      "Epoch [37/100], Step [400/938], Loss: 0.0346\n",
      "Epoch [37/100], Step [500/938], Loss: 0.0248\n",
      "Epoch [37/100], Step [600/938], Loss: 0.0274\n",
      "Epoch [37/100], Step [700/938], Loss: 0.1054\n",
      "Epoch [37/100], Step [800/938], Loss: 0.0300\n",
      "Epoch [37/100], Step [900/938], Loss: 0.0256\n",
      "Test Accuracy: 97.74%\n",
      "Epoch [38/100], Step [100/938], Loss: 0.0327\n",
      "Epoch [38/100], Step [200/938], Loss: 0.0186\n",
      "Epoch [38/100], Step [300/938], Loss: 0.0594\n",
      "Epoch [38/100], Step [400/938], Loss: 0.0375\n",
      "Epoch [38/100], Step [500/938], Loss: 0.0303\n",
      "Epoch [38/100], Step [600/938], Loss: 0.0396\n",
      "Epoch [38/100], Step [700/938], Loss: 0.0298\n",
      "Epoch [38/100], Step [800/938], Loss: 0.0722\n",
      "Epoch [38/100], Step [900/938], Loss: 0.0641\n",
      "Test Accuracy: 97.81%\n",
      "Epoch [39/100], Step [100/938], Loss: 0.0192\n",
      "Epoch [39/100], Step [200/938], Loss: 0.0332\n",
      "Epoch [39/100], Step [300/938], Loss: 0.0249\n",
      "Epoch [39/100], Step [400/938], Loss: 0.0399\n",
      "Epoch [39/100], Step [500/938], Loss: 0.0278\n",
      "Epoch [39/100], Step [600/938], Loss: 0.0353\n",
      "Epoch [39/100], Step [700/938], Loss: 0.0376\n",
      "Epoch [39/100], Step [800/938], Loss: 0.0087\n",
      "Epoch [39/100], Step [900/938], Loss: 0.0287\n",
      "Test Accuracy: 97.74%\n",
      "Epoch [40/100], Step [100/938], Loss: 0.0709\n",
      "Epoch [40/100], Step [200/938], Loss: 0.0201\n",
      "Epoch [40/100], Step [300/938], Loss: 0.0403\n",
      "Epoch [40/100], Step [400/938], Loss: 0.0264\n",
      "Epoch [40/100], Step [500/938], Loss: 0.0152\n",
      "Epoch [40/100], Step [600/938], Loss: 0.0080\n",
      "Epoch [40/100], Step [700/938], Loss: 0.0390\n",
      "Epoch [40/100], Step [800/938], Loss: 0.0254\n",
      "Epoch [40/100], Step [900/938], Loss: 0.0257\n",
      "Test Accuracy: 97.80%\n",
      "Epoch [41/100], Step [100/938], Loss: 0.0155\n",
      "Epoch [41/100], Step [200/938], Loss: 0.0156\n",
      "Epoch [41/100], Step [300/938], Loss: 0.0142\n",
      "Epoch [41/100], Step [400/938], Loss: 0.0563\n",
      "Epoch [41/100], Step [500/938], Loss: 0.0079\n",
      "Epoch [41/100], Step [600/938], Loss: 0.0130\n",
      "Epoch [41/100], Step [700/938], Loss: 0.0126\n",
      "Epoch [41/100], Step [800/938], Loss: 0.0382\n",
      "Epoch [41/100], Step [900/938], Loss: 0.0075\n",
      "Test Accuracy: 97.84%\n",
      "Epoch [42/100], Step [100/938], Loss: 0.0140\n",
      "Epoch [42/100], Step [200/938], Loss: 0.0297\n",
      "Epoch [42/100], Step [300/938], Loss: 0.0509\n",
      "Epoch [42/100], Step [400/938], Loss: 0.0137\n",
      "Epoch [42/100], Step [500/938], Loss: 0.0425\n",
      "Epoch [42/100], Step [600/938], Loss: 0.1205\n",
      "Epoch [42/100], Step [700/938], Loss: 0.0402\n",
      "Epoch [42/100], Step [800/938], Loss: 0.0329\n",
      "Epoch [42/100], Step [900/938], Loss: 0.0331\n",
      "Test Accuracy: 97.84%\n",
      "Epoch [43/100], Step [100/938], Loss: 0.0243\n",
      "Epoch [43/100], Step [200/938], Loss: 0.0068\n",
      "Epoch [43/100], Step [300/938], Loss: 0.0106\n",
      "Epoch [43/100], Step [400/938], Loss: 0.0445\n",
      "Epoch [43/100], Step [500/938], Loss: 0.0405\n",
      "Epoch [43/100], Step [600/938], Loss: 0.0442\n",
      "Epoch [43/100], Step [700/938], Loss: 0.0359\n",
      "Epoch [43/100], Step [800/938], Loss: 0.0144\n",
      "Epoch [43/100], Step [900/938], Loss: 0.0201\n",
      "Test Accuracy: 97.69%\n",
      "Epoch [44/100], Step [100/938], Loss: 0.0114\n",
      "Epoch [44/100], Step [200/938], Loss: 0.0185\n",
      "Epoch [44/100], Step [300/938], Loss: 0.0405\n",
      "Epoch [44/100], Step [400/938], Loss: 0.0176\n",
      "Epoch [44/100], Step [500/938], Loss: 0.0152\n",
      "Epoch [44/100], Step [600/938], Loss: 0.0273\n",
      "Epoch [44/100], Step [700/938], Loss: 0.0101\n",
      "Epoch [44/100], Step [800/938], Loss: 0.0075\n",
      "Epoch [44/100], Step [900/938], Loss: 0.0431\n",
      "Test Accuracy: 97.85%\n",
      "Epoch [45/100], Step [100/938], Loss: 0.0326\n",
      "Epoch [45/100], Step [200/938], Loss: 0.0244\n",
      "Epoch [45/100], Step [300/938], Loss: 0.0174\n",
      "Epoch [45/100], Step [400/938], Loss: 0.0159\n",
      "Epoch [45/100], Step [500/938], Loss: 0.0436\n",
      "Epoch [45/100], Step [600/938], Loss: 0.0439\n",
      "Epoch [45/100], Step [700/938], Loss: 0.0146\n",
      "Epoch [45/100], Step [800/938], Loss: 0.0070\n",
      "Epoch [45/100], Step [900/938], Loss: 0.0213\n",
      "Test Accuracy: 97.84%\n",
      "Epoch [46/100], Step [100/938], Loss: 0.0494\n",
      "Epoch [46/100], Step [200/938], Loss: 0.0209\n",
      "Epoch [46/100], Step [300/938], Loss: 0.0098\n",
      "Epoch [46/100], Step [400/938], Loss: 0.0330\n",
      "Epoch [46/100], Step [500/938], Loss: 0.0068\n",
      "Epoch [46/100], Step [600/938], Loss: 0.0086\n",
      "Epoch [46/100], Step [700/938], Loss: 0.1450\n",
      "Epoch [46/100], Step [800/938], Loss: 0.0056\n",
      "Epoch [46/100], Step [900/938], Loss: 0.0172\n",
      "Test Accuracy: 97.88%\n",
      "Epoch [47/100], Step [100/938], Loss: 0.0127\n",
      "Epoch [47/100], Step [200/938], Loss: 0.0082\n",
      "Epoch [47/100], Step [300/938], Loss: 0.0160\n",
      "Epoch [47/100], Step [400/938], Loss: 0.0282\n",
      "Epoch [47/100], Step [500/938], Loss: 0.0165\n",
      "Epoch [47/100], Step [600/938], Loss: 0.0134\n",
      "Epoch [47/100], Step [700/938], Loss: 0.0533\n",
      "Epoch [47/100], Step [800/938], Loss: 0.0150\n",
      "Epoch [47/100], Step [900/938], Loss: 0.0160\n",
      "Test Accuracy: 97.83%\n",
      "Epoch [48/100], Step [100/938], Loss: 0.0068\n",
      "Epoch [48/100], Step [200/938], Loss: 0.0281\n",
      "Epoch [48/100], Step [300/938], Loss: 0.0164\n",
      "Epoch [48/100], Step [400/938], Loss: 0.0115\n",
      "Epoch [48/100], Step [500/938], Loss: 0.0359\n",
      "Epoch [48/100], Step [600/938], Loss: 0.0133\n",
      "Epoch [48/100], Step [700/938], Loss: 0.0112\n",
      "Epoch [48/100], Step [800/938], Loss: 0.0156\n",
      "Epoch [48/100], Step [900/938], Loss: 0.0253\n",
      "Test Accuracy: 97.85%\n",
      "Epoch [49/100], Step [100/938], Loss: 0.0172\n",
      "Epoch [49/100], Step [200/938], Loss: 0.0172\n",
      "Epoch [49/100], Step [300/938], Loss: 0.0155\n",
      "Epoch [49/100], Step [400/938], Loss: 0.0267\n",
      "Epoch [49/100], Step [500/938], Loss: 0.0171\n",
      "Epoch [49/100], Step [600/938], Loss: 0.0250\n",
      "Epoch [49/100], Step [700/938], Loss: 0.0797\n",
      "Epoch [49/100], Step [800/938], Loss: 0.0135\n",
      "Epoch [49/100], Step [900/938], Loss: 0.0065\n",
      "Test Accuracy: 97.88%\n",
      "Epoch [50/100], Step [100/938], Loss: 0.0510\n",
      "Epoch [50/100], Step [200/938], Loss: 0.0305\n",
      "Epoch [50/100], Step [300/938], Loss: 0.0217\n",
      "Epoch [50/100], Step [400/938], Loss: 0.0338\n",
      "Epoch [50/100], Step [500/938], Loss: 0.0320\n",
      "Epoch [50/100], Step [600/938], Loss: 0.0074\n",
      "Epoch [50/100], Step [700/938], Loss: 0.0048\n",
      "Epoch [50/100], Step [800/938], Loss: 0.0086\n",
      "Epoch [50/100], Step [900/938], Loss: 0.0124\n",
      "Test Accuracy: 97.85%\n",
      "Epoch [51/100], Step [100/938], Loss: 0.0311\n",
      "Epoch [51/100], Step [200/938], Loss: 0.0098\n",
      "Epoch [51/100], Step [300/938], Loss: 0.0404\n",
      "Epoch [51/100], Step [400/938], Loss: 0.0080\n",
      "Epoch [51/100], Step [500/938], Loss: 0.0303\n",
      "Epoch [51/100], Step [600/938], Loss: 0.0370\n",
      "Epoch [51/100], Step [700/938], Loss: 0.0259\n",
      "Epoch [51/100], Step [800/938], Loss: 0.0131\n",
      "Epoch [51/100], Step [900/938], Loss: 0.0301\n",
      "Test Accuracy: 97.88%\n",
      "Epoch [52/100], Step [100/938], Loss: 0.1106\n",
      "Epoch [52/100], Step [200/938], Loss: 0.0262\n",
      "Epoch [52/100], Step [300/938], Loss: 0.0121\n",
      "Epoch [52/100], Step [400/938], Loss: 0.0125\n",
      "Epoch [52/100], Step [500/938], Loss: 0.0319\n",
      "Epoch [52/100], Step [600/938], Loss: 0.0090\n",
      "Epoch [52/100], Step [700/938], Loss: 0.0671\n",
      "Epoch [52/100], Step [800/938], Loss: 0.0073\n",
      "Epoch [52/100], Step [900/938], Loss: 0.0133\n",
      "Test Accuracy: 97.82%\n",
      "Epoch [53/100], Step [100/938], Loss: 0.0179\n",
      "Epoch [53/100], Step [200/938], Loss: 0.0503\n",
      "Epoch [53/100], Step [300/938], Loss: 0.0037\n",
      "Epoch [53/100], Step [400/938], Loss: 0.0330\n",
      "Epoch [53/100], Step [500/938], Loss: 0.0052\n",
      "Epoch [53/100], Step [600/938], Loss: 0.0091\n",
      "Epoch [53/100], Step [700/938], Loss: 0.0063\n",
      "Epoch [53/100], Step [800/938], Loss: 0.0116\n",
      "Epoch [53/100], Step [900/938], Loss: 0.0204\n",
      "Test Accuracy: 97.87%\n",
      "Epoch [54/100], Step [100/938], Loss: 0.0665\n",
      "Epoch [54/100], Step [200/938], Loss: 0.0184\n",
      "Epoch [54/100], Step [300/938], Loss: 0.0219\n",
      "Epoch [54/100], Step [400/938], Loss: 0.0156\n",
      "Epoch [54/100], Step [500/938], Loss: 0.0106\n",
      "Epoch [54/100], Step [600/938], Loss: 0.0128\n",
      "Epoch [54/100], Step [700/938], Loss: 0.0193\n",
      "Epoch [54/100], Step [800/938], Loss: 0.0095\n",
      "Epoch [54/100], Step [900/938], Loss: 0.0152\n",
      "Test Accuracy: 97.86%\n",
      "Epoch [55/100], Step [100/938], Loss: 0.0308\n",
      "Epoch [55/100], Step [200/938], Loss: 0.0172\n",
      "Epoch [55/100], Step [300/938], Loss: 0.0162\n",
      "Epoch [55/100], Step [400/938], Loss: 0.0195\n",
      "Epoch [55/100], Step [500/938], Loss: 0.0105\n",
      "Epoch [55/100], Step [600/938], Loss: 0.0209\n",
      "Epoch [55/100], Step [700/938], Loss: 0.0171\n",
      "Epoch [55/100], Step [800/938], Loss: 0.0175\n",
      "Epoch [55/100], Step [900/938], Loss: 0.0120\n",
      "Test Accuracy: 97.84%\n",
      "Epoch [56/100], Step [100/938], Loss: 0.0070\n",
      "Epoch [56/100], Step [200/938], Loss: 0.0111\n",
      "Epoch [56/100], Step [300/938], Loss: 0.0288\n",
      "Epoch [56/100], Step [400/938], Loss: 0.0436\n",
      "Epoch [56/100], Step [500/938], Loss: 0.0263\n",
      "Epoch [56/100], Step [600/938], Loss: 0.0402\n",
      "Epoch [56/100], Step [700/938], Loss: 0.0128\n",
      "Epoch [56/100], Step [800/938], Loss: 0.0156\n",
      "Epoch [56/100], Step [900/938], Loss: 0.0100\n",
      "Test Accuracy: 97.80%\n",
      "Epoch [57/100], Step [100/938], Loss: 0.0178\n",
      "Epoch [57/100], Step [200/938], Loss: 0.0099\n",
      "Epoch [57/100], Step [300/938], Loss: 0.0183\n",
      "Epoch [57/100], Step [400/938], Loss: 0.0235\n",
      "Epoch [57/100], Step [500/938], Loss: 0.0261\n",
      "Epoch [57/100], Step [600/938], Loss: 0.0180\n",
      "Epoch [57/100], Step [700/938], Loss: 0.0120\n",
      "Epoch [57/100], Step [800/938], Loss: 0.0162\n",
      "Epoch [57/100], Step [900/938], Loss: 0.0177\n",
      "Test Accuracy: 97.89%\n",
      "Epoch [58/100], Step [100/938], Loss: 0.0541\n",
      "Epoch [58/100], Step [200/938], Loss: 0.0178\n",
      "Epoch [58/100], Step [300/938], Loss: 0.0044\n",
      "Epoch [58/100], Step [400/938], Loss: 0.0156\n",
      "Epoch [58/100], Step [500/938], Loss: 0.0096\n",
      "Epoch [58/100], Step [600/938], Loss: 0.0177\n",
      "Epoch [58/100], Step [700/938], Loss: 0.0165\n",
      "Epoch [58/100], Step [800/938], Loss: 0.0137\n",
      "Epoch [58/100], Step [900/938], Loss: 0.0517\n",
      "Test Accuracy: 97.89%\n",
      "Epoch [59/100], Step [100/938], Loss: 0.0077\n",
      "Epoch [59/100], Step [200/938], Loss: 0.0143\n",
      "Epoch [59/100], Step [300/938], Loss: 0.0478\n",
      "Epoch [59/100], Step [400/938], Loss: 0.0316\n",
      "Epoch [59/100], Step [500/938], Loss: 0.0165\n",
      "Epoch [59/100], Step [600/938], Loss: 0.0083\n",
      "Epoch [59/100], Step [700/938], Loss: 0.0208\n",
      "Epoch [59/100], Step [800/938], Loss: 0.0075\n",
      "Epoch [59/100], Step [900/938], Loss: 0.0447\n",
      "Test Accuracy: 97.89%\n",
      "Epoch [60/100], Step [100/938], Loss: 0.0132\n",
      "Epoch [60/100], Step [200/938], Loss: 0.0133\n",
      "Epoch [60/100], Step [300/938], Loss: 0.0178\n",
      "Epoch [60/100], Step [400/938], Loss: 0.0290\n",
      "Epoch [60/100], Step [500/938], Loss: 0.0066\n",
      "Epoch [60/100], Step [600/938], Loss: 0.0058\n",
      "Epoch [60/100], Step [700/938], Loss: 0.0073\n",
      "Epoch [60/100], Step [800/938], Loss: 0.0082\n",
      "Epoch [60/100], Step [900/938], Loss: 0.0294\n",
      "Test Accuracy: 97.85%\n",
      "Epoch [61/100], Step [100/938], Loss: 0.0115\n",
      "Epoch [61/100], Step [200/938], Loss: 0.0142\n",
      "Epoch [61/100], Step [300/938], Loss: 0.0160\n",
      "Epoch [61/100], Step [400/938], Loss: 0.0065\n",
      "Epoch [61/100], Step [500/938], Loss: 0.0153\n",
      "Epoch [61/100], Step [600/938], Loss: 0.0500\n",
      "Epoch [61/100], Step [700/938], Loss: 0.0159\n",
      "Epoch [61/100], Step [800/938], Loss: 0.0216\n",
      "Epoch [61/100], Step [900/938], Loss: 0.0304\n",
      "Test Accuracy: 97.87%\n",
      "Epoch [62/100], Step [100/938], Loss: 0.0189\n",
      "Epoch [62/100], Step [200/938], Loss: 0.0270\n",
      "Epoch [62/100], Step [300/938], Loss: 0.0219\n",
      "Epoch [62/100], Step [400/938], Loss: 0.0216\n",
      "Epoch [62/100], Step [500/938], Loss: 0.0122\n",
      "Epoch [62/100], Step [600/938], Loss: 0.0066\n",
      "Epoch [62/100], Step [700/938], Loss: 0.0058\n",
      "Epoch [62/100], Step [800/938], Loss: 0.0104\n",
      "Epoch [62/100], Step [900/938], Loss: 0.0071\n",
      "Test Accuracy: 97.91%\n",
      "Epoch [63/100], Step [100/938], Loss: 0.0179\n",
      "Epoch [63/100], Step [200/938], Loss: 0.0164\n",
      "Epoch [63/100], Step [300/938], Loss: 0.0254\n",
      "Epoch [63/100], Step [400/938], Loss: 0.0111\n",
      "Epoch [63/100], Step [500/938], Loss: 0.0218\n",
      "Epoch [63/100], Step [600/938], Loss: 0.0073\n",
      "Epoch [63/100], Step [700/938], Loss: 0.0048\n",
      "Epoch [63/100], Step [800/938], Loss: 0.0179\n",
      "Epoch [63/100], Step [900/938], Loss: 0.0287\n",
      "Test Accuracy: 97.91%\n",
      "Epoch [64/100], Step [100/938], Loss: 0.0209\n",
      "Epoch [64/100], Step [200/938], Loss: 0.0209\n",
      "Epoch [64/100], Step [300/938], Loss: 0.0065\n",
      "Epoch [64/100], Step [400/938], Loss: 0.0165\n",
      "Epoch [64/100], Step [500/938], Loss: 0.0113\n",
      "Epoch [64/100], Step [600/938], Loss: 0.0214\n",
      "Epoch [64/100], Step [700/938], Loss: 0.0156\n",
      "Epoch [64/100], Step [800/938], Loss: 0.0141\n",
      "Epoch [64/100], Step [900/938], Loss: 0.0241\n",
      "Test Accuracy: 97.91%\n",
      "Epoch [65/100], Step [100/938], Loss: 0.0081\n",
      "Epoch [65/100], Step [200/938], Loss: 0.0098\n",
      "Epoch [65/100], Step [300/938], Loss: 0.0140\n",
      "Epoch [65/100], Step [400/938], Loss: 0.0076\n",
      "Epoch [65/100], Step [500/938], Loss: 0.0858\n",
      "Epoch [65/100], Step [600/938], Loss: 0.0087\n",
      "Epoch [65/100], Step [700/938], Loss: 0.0147\n",
      "Epoch [65/100], Step [800/938], Loss: 0.0038\n",
      "Epoch [65/100], Step [900/938], Loss: 0.0104\n",
      "Test Accuracy: 97.88%\n",
      "Epoch [66/100], Step [100/938], Loss: 0.0172\n",
      "Epoch [66/100], Step [200/938], Loss: 0.0161\n",
      "Epoch [66/100], Step [300/938], Loss: 0.0189\n",
      "Epoch [66/100], Step [400/938], Loss: 0.0171\n",
      "Epoch [66/100], Step [500/938], Loss: 0.0231\n",
      "Epoch [66/100], Step [600/938], Loss: 0.0030\n",
      "Epoch [66/100], Step [700/938], Loss: 0.0225\n",
      "Epoch [66/100], Step [800/938], Loss: 0.0175\n",
      "Epoch [66/100], Step [900/938], Loss: 0.0283\n",
      "Test Accuracy: 97.87%\n",
      "Epoch [67/100], Step [100/938], Loss: 0.0181\n",
      "Epoch [67/100], Step [200/938], Loss: 0.0104\n",
      "Epoch [67/100], Step [300/938], Loss: 0.0124\n",
      "Epoch [67/100], Step [400/938], Loss: 0.0271\n",
      "Epoch [67/100], Step [500/938], Loss: 0.0110\n",
      "Epoch [67/100], Step [600/938], Loss: 0.0113\n",
      "Epoch [67/100], Step [700/938], Loss: 0.0046\n",
      "Epoch [67/100], Step [800/938], Loss: 0.0118\n",
      "Epoch [67/100], Step [900/938], Loss: 0.0120\n",
      "Test Accuracy: 97.91%\n",
      "Epoch [68/100], Step [100/938], Loss: 0.0080\n",
      "Epoch [68/100], Step [200/938], Loss: 0.0087\n",
      "Epoch [68/100], Step [300/938], Loss: 0.0113\n",
      "Epoch [68/100], Step [400/938], Loss: 0.0043\n",
      "Epoch [68/100], Step [500/938], Loss: 0.0375\n",
      "Epoch [68/100], Step [600/938], Loss: 0.0176\n",
      "Epoch [68/100], Step [700/938], Loss: 0.0115\n",
      "Epoch [68/100], Step [800/938], Loss: 0.0189\n",
      "Epoch [68/100], Step [900/938], Loss: 0.0315\n",
      "Test Accuracy: 97.93%\n",
      "Epoch [69/100], Step [100/938], Loss: 0.0113\n",
      "Epoch [69/100], Step [200/938], Loss: 0.0071\n",
      "Epoch [69/100], Step [300/938], Loss: 0.0029\n",
      "Epoch [69/100], Step [400/938], Loss: 0.0193\n",
      "Epoch [69/100], Step [500/938], Loss: 0.0142\n",
      "Epoch [69/100], Step [600/938], Loss: 0.0123\n",
      "Epoch [69/100], Step [700/938], Loss: 0.0111\n",
      "Epoch [69/100], Step [800/938], Loss: 0.0102\n",
      "Epoch [69/100], Step [900/938], Loss: 0.0047\n",
      "Test Accuracy: 97.89%\n",
      "Epoch [70/100], Step [100/938], Loss: 0.0013\n",
      "Epoch [70/100], Step [200/938], Loss: 0.0156\n",
      "Epoch [70/100], Step [300/938], Loss: 0.0078\n",
      "Epoch [70/100], Step [400/938], Loss: 0.0442\n",
      "Epoch [70/100], Step [500/938], Loss: 0.0177\n",
      "Epoch [70/100], Step [600/938], Loss: 0.0096\n",
      "Epoch [70/100], Step [700/938], Loss: 0.0428\n",
      "Epoch [70/100], Step [800/938], Loss: 0.0153\n",
      "Epoch [70/100], Step [900/938], Loss: 0.0266\n",
      "Test Accuracy: 97.91%\n",
      "Epoch [71/100], Step [100/938], Loss: 0.0089\n",
      "Epoch [71/100], Step [200/938], Loss: 0.0083\n",
      "Epoch [71/100], Step [300/938], Loss: 0.0073\n",
      "Epoch [71/100], Step [400/938], Loss: 0.0062\n",
      "Epoch [71/100], Step [500/938], Loss: 0.0049\n",
      "Epoch [71/100], Step [600/938], Loss: 0.0016\n",
      "Epoch [71/100], Step [700/938], Loss: 0.0108\n",
      "Epoch [71/100], Step [800/938], Loss: 0.0037\n",
      "Epoch [71/100], Step [900/938], Loss: 0.0072\n",
      "Test Accuracy: 97.92%\n",
      "Epoch [72/100], Step [100/938], Loss: 0.0119\n",
      "Epoch [72/100], Step [200/938], Loss: 0.0193\n",
      "Epoch [72/100], Step [300/938], Loss: 0.0051\n",
      "Epoch [72/100], Step [400/938], Loss: 0.0054\n",
      "Epoch [72/100], Step [500/938], Loss: 0.0183\n",
      "Epoch [72/100], Step [600/938], Loss: 0.0109\n",
      "Epoch [72/100], Step [700/938], Loss: 0.0090\n",
      "Epoch [72/100], Step [800/938], Loss: 0.0157\n",
      "Epoch [72/100], Step [900/938], Loss: 0.0086\n",
      "Test Accuracy: 97.95%\n",
      "Epoch [73/100], Step [100/938], Loss: 0.0089\n",
      "Epoch [73/100], Step [200/938], Loss: 0.0121\n",
      "Epoch [73/100], Step [300/938], Loss: 0.0144\n",
      "Epoch [73/100], Step [400/938], Loss: 0.0130\n",
      "Epoch [73/100], Step [500/938], Loss: 0.0020\n",
      "Epoch [73/100], Step [600/938], Loss: 0.0073\n",
      "Epoch [73/100], Step [700/938], Loss: 0.0079\n",
      "Epoch [73/100], Step [800/938], Loss: 0.0232\n",
      "Epoch [73/100], Step [900/938], Loss: 0.0118\n",
      "Test Accuracy: 97.94%\n",
      "Epoch [74/100], Step [100/938], Loss: 0.0077\n",
      "Epoch [74/100], Step [200/938], Loss: 0.0200\n",
      "Epoch [74/100], Step [300/938], Loss: 0.0099\n",
      "Epoch [74/100], Step [400/938], Loss: 0.0181\n",
      "Epoch [74/100], Step [500/938], Loss: 0.0022\n",
      "Epoch [74/100], Step [600/938], Loss: 0.0148\n",
      "Epoch [74/100], Step [700/938], Loss: 0.0118\n",
      "Epoch [74/100], Step [800/938], Loss: 0.0194\n",
      "Epoch [74/100], Step [900/938], Loss: 0.0113\n",
      "Test Accuracy: 97.94%\n",
      "Epoch [75/100], Step [100/938], Loss: 0.0226\n",
      "Epoch [75/100], Step [200/938], Loss: 0.0052\n",
      "Epoch [75/100], Step [300/938], Loss: 0.0127\n",
      "Epoch [75/100], Step [400/938], Loss: 0.0215\n",
      "Epoch [75/100], Step [500/938], Loss: 0.0102\n",
      "Epoch [75/100], Step [600/938], Loss: 0.0033\n",
      "Epoch [75/100], Step [700/938], Loss: 0.0139\n",
      "Epoch [75/100], Step [800/938], Loss: 0.0073\n",
      "Epoch [75/100], Step [900/938], Loss: 0.0211\n",
      "Test Accuracy: 97.94%\n",
      "Epoch [76/100], Step [100/938], Loss: 0.0139\n",
      "Epoch [76/100], Step [200/938], Loss: 0.0090\n",
      "Epoch [76/100], Step [300/938], Loss: 0.0185\n",
      "Epoch [76/100], Step [400/938], Loss: 0.0383\n",
      "Epoch [76/100], Step [500/938], Loss: 0.0067\n",
      "Epoch [76/100], Step [600/938], Loss: 0.0152\n",
      "Epoch [76/100], Step [700/938], Loss: 0.0218\n",
      "Epoch [76/100], Step [800/938], Loss: 0.0078\n",
      "Epoch [76/100], Step [900/938], Loss: 0.0058\n",
      "Test Accuracy: 97.96%\n",
      "Epoch [77/100], Step [100/938], Loss: 0.0078\n",
      "Epoch [77/100], Step [200/938], Loss: 0.0149\n",
      "Epoch [77/100], Step [300/938], Loss: 0.0203\n",
      "Epoch [77/100], Step [400/938], Loss: 0.0222\n",
      "Epoch [77/100], Step [500/938], Loss: 0.0112\n",
      "Epoch [77/100], Step [600/938], Loss: 0.0218\n",
      "Epoch [77/100], Step [700/938], Loss: 0.0110\n",
      "Epoch [77/100], Step [800/938], Loss: 0.0073\n",
      "Epoch [77/100], Step [900/938], Loss: 0.0116\n",
      "Test Accuracy: 97.94%\n",
      "Epoch [78/100], Step [100/938], Loss: 0.0277\n",
      "Epoch [78/100], Step [200/938], Loss: 0.0109\n",
      "Epoch [78/100], Step [300/938], Loss: 0.0022\n",
      "Epoch [78/100], Step [400/938], Loss: 0.0040\n",
      "Epoch [78/100], Step [500/938], Loss: 0.0130\n",
      "Epoch [78/100], Step [600/938], Loss: 0.0300\n",
      "Epoch [78/100], Step [700/938], Loss: 0.0065\n",
      "Epoch [78/100], Step [800/938], Loss: 0.0072\n",
      "Epoch [78/100], Step [900/938], Loss: 0.0051\n",
      "Test Accuracy: 97.95%\n",
      "Epoch [79/100], Step [100/938], Loss: 0.0152\n",
      "Epoch [79/100], Step [200/938], Loss: 0.0074\n",
      "Epoch [79/100], Step [300/938], Loss: 0.0124\n",
      "Epoch [79/100], Step [400/938], Loss: 0.0095\n",
      "Epoch [79/100], Step [500/938], Loss: 0.0111\n",
      "Epoch [79/100], Step [600/938], Loss: 0.0014\n",
      "Epoch [79/100], Step [700/938], Loss: 0.0140\n",
      "Epoch [79/100], Step [800/938], Loss: 0.0048\n",
      "Epoch [79/100], Step [900/938], Loss: 0.0060\n",
      "Test Accuracy: 97.92%\n",
      "Epoch [80/100], Step [100/938], Loss: 0.0112\n",
      "Epoch [80/100], Step [200/938], Loss: 0.0322\n",
      "Epoch [80/100], Step [300/938], Loss: 0.0102\n",
      "Epoch [80/100], Step [400/938], Loss: 0.0114\n",
      "Epoch [80/100], Step [500/938], Loss: 0.0105\n",
      "Epoch [80/100], Step [600/938], Loss: 0.0082\n",
      "Epoch [80/100], Step [700/938], Loss: 0.0106\n",
      "Epoch [80/100], Step [800/938], Loss: 0.0089\n",
      "Epoch [80/100], Step [900/938], Loss: 0.0152\n",
      "Test Accuracy: 97.94%\n",
      "Epoch [81/100], Step [100/938], Loss: 0.0161\n",
      "Epoch [81/100], Step [200/938], Loss: 0.0133\n",
      "Epoch [81/100], Step [300/938], Loss: 0.0362\n",
      "Epoch [81/100], Step [400/938], Loss: 0.0103\n",
      "Epoch [81/100], Step [500/938], Loss: 0.0265\n",
      "Epoch [81/100], Step [600/938], Loss: 0.0187\n",
      "Epoch [81/100], Step [700/938], Loss: 0.0136\n",
      "Epoch [81/100], Step [800/938], Loss: 0.0139\n",
      "Epoch [81/100], Step [900/938], Loss: 0.0035\n",
      "Test Accuracy: 97.94%\n",
      "Epoch [82/100], Step [100/938], Loss: 0.0133\n",
      "Epoch [82/100], Step [200/938], Loss: 0.0177\n",
      "Epoch [82/100], Step [300/938], Loss: 0.0032\n",
      "Epoch [82/100], Step [400/938], Loss: 0.0100\n",
      "Epoch [82/100], Step [500/938], Loss: 0.0027\n",
      "Epoch [82/100], Step [600/938], Loss: 0.0114\n",
      "Epoch [82/100], Step [700/938], Loss: 0.0202\n",
      "Epoch [82/100], Step [800/938], Loss: 0.0039\n",
      "Epoch [82/100], Step [900/938], Loss: 0.0106\n",
      "Test Accuracy: 97.99%\n",
      "Epoch [83/100], Step [100/938], Loss: 0.0187\n",
      "Epoch [83/100], Step [200/938], Loss: 0.0076\n",
      "Epoch [83/100], Step [300/938], Loss: 0.0063\n",
      "Epoch [83/100], Step [400/938], Loss: 0.0089\n",
      "Epoch [83/100], Step [500/938], Loss: 0.0053\n",
      "Epoch [83/100], Step [600/938], Loss: 0.0071\n",
      "Epoch [83/100], Step [700/938], Loss: 0.0134\n",
      "Epoch [83/100], Step [800/938], Loss: 0.0179\n",
      "Epoch [83/100], Step [900/938], Loss: 0.0134\n",
      "Test Accuracy: 97.94%\n",
      "Epoch [84/100], Step [100/938], Loss: 0.0064\n",
      "Epoch [84/100], Step [200/938], Loss: 0.0025\n",
      "Epoch [84/100], Step [300/938], Loss: 0.0088\n",
      "Epoch [84/100], Step [400/938], Loss: 0.0081\n",
      "Epoch [84/100], Step [500/938], Loss: 0.0116\n",
      "Epoch [84/100], Step [600/938], Loss: 0.0154\n",
      "Epoch [84/100], Step [700/938], Loss: 0.0204\n",
      "Epoch [84/100], Step [800/938], Loss: 0.0060\n",
      "Epoch [84/100], Step [900/938], Loss: 0.0068\n",
      "Test Accuracy: 97.95%\n",
      "Epoch [85/100], Step [100/938], Loss: 0.0088\n",
      "Epoch [85/100], Step [200/938], Loss: 0.0152\n",
      "Epoch [85/100], Step [300/938], Loss: 0.0171\n",
      "Epoch [85/100], Step [400/938], Loss: 0.0020\n",
      "Epoch [85/100], Step [500/938], Loss: 0.0127\n",
      "Epoch [85/100], Step [600/938], Loss: 0.0137\n",
      "Epoch [85/100], Step [700/938], Loss: 0.0253\n",
      "Epoch [85/100], Step [800/938], Loss: 0.0022\n",
      "Epoch [85/100], Step [900/938], Loss: 0.0052\n",
      "Test Accuracy: 97.93%\n",
      "Epoch [86/100], Step [100/938], Loss: 0.0135\n",
      "Epoch [86/100], Step [200/938], Loss: 0.0225\n",
      "Epoch [86/100], Step [300/938], Loss: 0.0076\n",
      "Epoch [86/100], Step [400/938], Loss: 0.0148\n",
      "Epoch [86/100], Step [500/938], Loss: 0.0115\n",
      "Epoch [86/100], Step [600/938], Loss: 0.0080\n",
      "Epoch [86/100], Step [700/938], Loss: 0.0107\n",
      "Epoch [86/100], Step [800/938], Loss: 0.0086\n",
      "Epoch [86/100], Step [900/938], Loss: 0.0107\n",
      "Test Accuracy: 98.01%\n",
      "Epoch [87/100], Step [100/938], Loss: 0.0071\n",
      "Epoch [87/100], Step [200/938], Loss: 0.0201\n",
      "Epoch [87/100], Step [300/938], Loss: 0.0084\n",
      "Epoch [87/100], Step [400/938], Loss: 0.0141\n",
      "Epoch [87/100], Step [500/938], Loss: 0.0044\n",
      "Epoch [87/100], Step [600/938], Loss: 0.0115\n",
      "Epoch [87/100], Step [700/938], Loss: 0.0087\n",
      "Epoch [87/100], Step [800/938], Loss: 0.0131\n",
      "Epoch [87/100], Step [900/938], Loss: 0.0123\n",
      "Test Accuracy: 97.99%\n",
      "Epoch [88/100], Step [100/938], Loss: 0.0278\n",
      "Epoch [88/100], Step [200/938], Loss: 0.0105\n",
      "Epoch [88/100], Step [300/938], Loss: 0.0158\n",
      "Epoch [88/100], Step [400/938], Loss: 0.0141\n",
      "Epoch [88/100], Step [500/938], Loss: 0.0095\n",
      "Epoch [88/100], Step [600/938], Loss: 0.0129\n",
      "Epoch [88/100], Step [700/938], Loss: 0.0113\n",
      "Epoch [88/100], Step [800/938], Loss: 0.0060\n",
      "Epoch [88/100], Step [900/938], Loss: 0.0368\n",
      "Test Accuracy: 97.95%\n",
      "Epoch [89/100], Step [100/938], Loss: 0.0054\n",
      "Epoch [89/100], Step [200/938], Loss: 0.0060\n",
      "Epoch [89/100], Step [300/938], Loss: 0.0049\n",
      "Epoch [89/100], Step [400/938], Loss: 0.0029\n",
      "Epoch [89/100], Step [500/938], Loss: 0.0101\n",
      "Epoch [89/100], Step [600/938], Loss: 0.0022\n",
      "Epoch [89/100], Step [700/938], Loss: 0.0259\n",
      "Epoch [89/100], Step [800/938], Loss: 0.0096\n",
      "Epoch [89/100], Step [900/938], Loss: 0.0051\n",
      "Test Accuracy: 97.94%\n",
      "Epoch [90/100], Step [100/938], Loss: 0.0251\n",
      "Epoch [90/100], Step [200/938], Loss: 0.0038\n",
      "Epoch [90/100], Step [300/938], Loss: 0.0054\n",
      "Epoch [90/100], Step [400/938], Loss: 0.0053\n",
      "Epoch [90/100], Step [500/938], Loss: 0.0051\n",
      "Epoch [90/100], Step [600/938], Loss: 0.0040\n",
      "Epoch [90/100], Step [700/938], Loss: 0.0537\n",
      "Epoch [90/100], Step [800/938], Loss: 0.0068\n",
      "Epoch [90/100], Step [900/938], Loss: 0.0032\n",
      "Test Accuracy: 97.98%\n",
      "Epoch [91/100], Step [100/938], Loss: 0.0123\n",
      "Epoch [91/100], Step [200/938], Loss: 0.0140\n",
      "Epoch [91/100], Step [300/938], Loss: 0.0173\n",
      "Epoch [91/100], Step [400/938], Loss: 0.0093\n",
      "Epoch [91/100], Step [500/938], Loss: 0.0063\n",
      "Epoch [91/100], Step [600/938], Loss: 0.0112\n",
      "Epoch [91/100], Step [700/938], Loss: 0.0253\n",
      "Epoch [91/100], Step [800/938], Loss: 0.0179\n",
      "Epoch [91/100], Step [900/938], Loss: 0.0206\n",
      "Test Accuracy: 97.95%\n",
      "Epoch [92/100], Step [100/938], Loss: 0.0017\n",
      "Epoch [92/100], Step [200/938], Loss: 0.0139\n",
      "Epoch [92/100], Step [300/938], Loss: 0.0093\n",
      "Epoch [92/100], Step [400/938], Loss: 0.0063\n",
      "Epoch [92/100], Step [500/938], Loss: 0.0088\n",
      "Epoch [92/100], Step [600/938], Loss: 0.0061\n",
      "Epoch [92/100], Step [700/938], Loss: 0.0043\n",
      "Epoch [92/100], Step [800/938], Loss: 0.0118\n",
      "Epoch [92/100], Step [900/938], Loss: 0.0020\n",
      "Test Accuracy: 98.01%\n",
      "Epoch [93/100], Step [100/938], Loss: 0.0095\n",
      "Epoch [93/100], Step [200/938], Loss: 0.0097\n",
      "Epoch [93/100], Step [300/938], Loss: 0.0047\n",
      "Epoch [93/100], Step [400/938], Loss: 0.0077\n",
      "Epoch [93/100], Step [500/938], Loss: 0.0057\n",
      "Epoch [93/100], Step [600/938], Loss: 0.0082\n",
      "Epoch [93/100], Step [700/938], Loss: 0.0156\n",
      "Epoch [93/100], Step [800/938], Loss: 0.0103\n",
      "Epoch [93/100], Step [900/938], Loss: 0.0029\n",
      "Test Accuracy: 98.01%\n",
      "Epoch [94/100], Step [100/938], Loss: 0.0102\n",
      "Epoch [94/100], Step [200/938], Loss: 0.0050\n",
      "Epoch [94/100], Step [300/938], Loss: 0.0060\n",
      "Epoch [94/100], Step [400/938], Loss: 0.0106\n",
      "Epoch [94/100], Step [500/938], Loss: 0.0054\n",
      "Epoch [94/100], Step [600/938], Loss: 0.0062\n",
      "Epoch [94/100], Step [700/938], Loss: 0.0081\n",
      "Epoch [94/100], Step [800/938], Loss: 0.0167\n",
      "Epoch [94/100], Step [900/938], Loss: 0.0098\n",
      "Test Accuracy: 98.00%\n",
      "Epoch [95/100], Step [100/938], Loss: 0.0075\n",
      "Epoch [95/100], Step [200/938], Loss: 0.0041\n",
      "Epoch [95/100], Step [300/938], Loss: 0.0261\n",
      "Epoch [95/100], Step [400/938], Loss: 0.0124\n",
      "Epoch [95/100], Step [500/938], Loss: 0.0022\n",
      "Epoch [95/100], Step [600/938], Loss: 0.0097\n",
      "Epoch [95/100], Step [700/938], Loss: 0.0062\n",
      "Epoch [95/100], Step [800/938], Loss: 0.0041\n",
      "Epoch [95/100], Step [900/938], Loss: 0.0073\n",
      "Test Accuracy: 98.01%\n",
      "Epoch [96/100], Step [100/938], Loss: 0.0112\n",
      "Epoch [96/100], Step [200/938], Loss: 0.0014\n",
      "Epoch [96/100], Step [300/938], Loss: 0.0427\n",
      "Epoch [96/100], Step [400/938], Loss: 0.0046\n",
      "Epoch [96/100], Step [500/938], Loss: 0.0047\n",
      "Epoch [96/100], Step [600/938], Loss: 0.0085\n",
      "Epoch [96/100], Step [700/938], Loss: 0.0036\n",
      "Epoch [96/100], Step [800/938], Loss: 0.0048\n",
      "Epoch [96/100], Step [900/938], Loss: 0.0027\n",
      "Test Accuracy: 98.02%\n",
      "Epoch [97/100], Step [100/938], Loss: 0.0059\n",
      "Epoch [97/100], Step [200/938], Loss: 0.0138\n",
      "Epoch [97/100], Step [300/938], Loss: 0.0098\n",
      "Epoch [97/100], Step [400/938], Loss: 0.0023\n",
      "Epoch [97/100], Step [500/938], Loss: 0.0156\n",
      "Epoch [97/100], Step [600/938], Loss: 0.0131\n",
      "Epoch [97/100], Step [700/938], Loss: 0.0079\n",
      "Epoch [97/100], Step [800/938], Loss: 0.0074\n",
      "Epoch [97/100], Step [900/938], Loss: 0.0200\n",
      "Test Accuracy: 97.98%\n",
      "Epoch [98/100], Step [100/938], Loss: 0.0081\n",
      "Epoch [98/100], Step [200/938], Loss: 0.0117\n",
      "Epoch [98/100], Step [300/938], Loss: 0.0053\n",
      "Epoch [98/100], Step [400/938], Loss: 0.0168\n",
      "Epoch [98/100], Step [500/938], Loss: 0.0107\n",
      "Epoch [98/100], Step [600/938], Loss: 0.0065\n",
      "Epoch [98/100], Step [700/938], Loss: 0.0089\n",
      "Epoch [98/100], Step [800/938], Loss: 0.0055\n",
      "Epoch [98/100], Step [900/938], Loss: 0.0080\n",
      "Test Accuracy: 98.01%\n",
      "Epoch [99/100], Step [100/938], Loss: 0.0208\n",
      "Epoch [99/100], Step [200/938], Loss: 0.0091\n",
      "Epoch [99/100], Step [300/938], Loss: 0.0419\n",
      "Epoch [99/100], Step [400/938], Loss: 0.0042\n",
      "Epoch [99/100], Step [500/938], Loss: 0.0072\n",
      "Epoch [99/100], Step [600/938], Loss: 0.0069\n",
      "Epoch [99/100], Step [700/938], Loss: 0.0102\n",
      "Epoch [99/100], Step [800/938], Loss: 0.0047\n",
      "Epoch [99/100], Step [900/938], Loss: 0.0020\n",
      "Test Accuracy: 98.04%\n",
      "Epoch [100/100], Step [100/938], Loss: 0.0013\n",
      "Epoch [100/100], Step [200/938], Loss: 0.0228\n",
      "Epoch [100/100], Step [300/938], Loss: 0.0072\n",
      "Epoch [100/100], Step [400/938], Loss: 0.0089\n",
      "Epoch [100/100], Step [500/938], Loss: 0.0041\n",
      "Epoch [100/100], Step [600/938], Loss: 0.0018\n",
      "Epoch [100/100], Step [700/938], Loss: 0.0087\n",
      "Epoch [100/100], Step [800/938], Loss: 0.0047\n",
      "Epoch [100/100], Step [900/938], Loss: 0.0109\n",
      "Test Accuracy: 98.00%\n",
      ": [9.4314051e-01 4.4935036e-02 8.8910451e-03 1.7794042e-03 5.8056065e-04\n",
      " 2.1271169e-04 9.7346528e-05 5.1755007e-05 3.4216599e-05 2.1676084e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 32047 (\\N{CJK UNIFIED IDEOGRAPH-7D2F}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 35745 (\\N{CJK UNIFIED IDEOGRAPH-8BA1}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 26041 (\\N{CJK UNIFIED IDEOGRAPH-65B9}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 24046 (\\N{CJK UNIFIED IDEOGRAPH-5DEE}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 27604 (\\N{CJK UNIFIED IDEOGRAPH-6BD4}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 20363 (\\N{CJK UNIFIED IDEOGRAPH-4F8B}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 26354 (\\N{CJK UNIFIED IDEOGRAPH-66F2}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 32447 (\\N{CJK UNIFIED IDEOGRAPH-7EBF}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 20027 (\\N{CJK UNIFIED IDEOGRAPH-4E3B}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 25104 (\\N{CJK UNIFIED IDEOGRAPH-6210}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 37327 (\\N{CJK UNIFIED IDEOGRAPH-91CF}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 31532 (\\N{CJK UNIFIED IDEOGRAPH-7B2C}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 20108 (\\N{CJK UNIFIED IDEOGRAPH-4E8C}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 20027 (\\N{CJK UNIFIED IDEOGRAPH-4E3B}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 25104 (\\N{CJK UNIFIED IDEOGRAPH-6210}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 21442 (\\N{CJK UNIFIED IDEOGRAPH-53C2}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 25968 (\\N{CJK UNIFIED IDEOGRAPH-6570}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 21464 (\\N{CJK UNIFIED IDEOGRAPH-53D8}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 21270 (\\N{CJK UNIFIED IDEOGRAPH-5316}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 30340 (\\N{CJK UNIFIED IDEOGRAPH-7684}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 20302 (\\N{CJK UNIFIED IDEOGRAPH-4F4E}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 32500 (\\N{CJK UNIFIED IDEOGRAPH-7EF4}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/mnt/data/user_liangzhiyu/envs/fedcsl/lib/python3.8/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 19968 (\\N{CJK UNIFIED IDEOGRAPH-4E00}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAFNCAYAAADo2q2EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAkfUlEQVR4nO3df3Db933f8dcbAAEKJGWFpM04tlmajZxY69Yl4bnk1evRa9Ilrq7e7dqrc13YJttpqdNc1XVbk1bXZndarnfrD6fNr3pp2vDqVsul7tWnOT/strwkK9lGstMkltNYY1hatmOLpC2RhAgQwHt/AKBACqBAgsQX+OL5uOOJ/OJL8qOPab34+Xzen8/X3F0AACCcIkE3AAAA7B+CHgCAECPoAQAIMYIeAIAQI+gBAAgxgh4AgBAj6AEACLFY0A0AsHfM7D5J/7XCS1+S9GMVrr/o7j9lZn8pqa/C6z8p6b2S3lrhtf8hKV7l+z0m6U8k/Wkjv6e7f7jCdaCtEfRAuNws6UPu/kTpgpl1S/qUpCl3P1F+s5l9rvjuurvfveW135LUKemNksbdPVv22lFJA8XXK32/j0pKBvA9AWzB1D0AACFG0AMAEGIEPQAAIUbQAwAQYgQ9AAAhRtADABBiBD0AACFG0AMAEGIcmAOEz2+b2StlH0clPS/pXWZ295Z7SyfT/XMzm9ry2vfr6iE0f2VmvuXzfnub7/f/iu8H8T0BlDF3v/5dAACgJTF1DwBAiBH0AACEGEEPAECIhbIYr7+/34eGhoJuRtNYXV1VV1dX0M1oSfRdfei/+tB/u9dufXf27NkFd7+x0muhDPqhoSGdOXMm6GY0jampKY2PjwfdjJZE39WH/qsP/bd77dZ3ZvZP1V5j6h4AgBAj6AEACDGCHgCAECPoAQAIMYIeAIAQI+gBAAgxgh4AgBAL5T56AACa0czsoian5zS/lNJgb1ITY0MaHe67/ifWgRE9AAANMDO7qJOnz2lhOaMbuxNaWM7o5Olzmpld3NfvS9ADANAAk9NzSsZj6umMKWKmns6YkvGYJqfn9vX7EvQAADTA/FJKXYnopmtdiajml1L7+n0JegAAGmCwN6nVdG7TtdV0ToO9yX39vgQ9AAANMDE2pFQmq+W1rPLuWl7LKpXJamJsaF+/L0EPAEADjA736cTRI+rvieviSlr9PXGdOHpk36vu2V4HAECDjA737Xuwb8WIHgCAECPoAQAIMYIeAIAQI+gBAAgxgh4AgBALLOjN7DYz+xsze8bMnjazX6xwj5nZ75nZeTP7hpm9OYi2AgDQqoLcXpeV9Mvu/qSZ9Ug6a2aPu/u5snveIelw8e2HJH2i+CcAAKhBYCN6d3/R3Z8svr8s6RlJt2y57T5Jk14wI+mQmd3c4KYCANCymmKN3syGJL1J0t9teekWSc+VfXxB1/4yAAAAqgj8ZDwz65b055KOu/vlrS9X+BSv8nWOSTomSQMDA5qamtrLZra0lZUV+mOX6Lv60H/1of92j767KtCgN7MOFUL+YXd/pMItFyTdVvbxrZJeqPS13P0hSQ9J0sjIiI+Pj+9tY1vY1NSU6I/doe/qQ//Vh/7bPfruqiCr7k3SH0p6xt1/p8ptj0qaKFbfj0q65O4vNqyRAAC0uCBH9D8s6V2SvmlmXy9e+1VJg5Lk7p+U9JikeyWdl5SS9O7GNxMAgNYVWNC7+1dVeQ2+/B6X9L7GtAgAgPBpiqp7AACwPwKvugcAoBXNzC5qcnpO80spDfYmNTE21PBnzdeCET0AADs0M7uok6fPaWE5oxu7E1pYzujk6XOamV0MumnXIOgBANihyek5JeMx9XTGFDFTT2dMyXhMk9NzQTftGgQ9AAA7NL+UUlciuulaVyKq+aVUQC2qjqAHAGCHBnuTWk3nNl1bTec02JsMqEXVEfQAAOzQxNiQUpmslteyyrtreS2rVCaribGhoJt2DYIeAIAdGh3u04mjR9TfE9fFlbT6e+I6cfRIU1bds70OAIBdGB3ua8pg34oRPQAAIUbQAwAQYgQ9AAAhRtADABBiBD0AACFG0AMAEGIEPQAAIUbQAwAQYgQ9AAAhRtADABBiBD0AACFG0AMAEGIEPQAAIUbQAwAQYgQ9AAAhRtADABBiBD0AACEWC7oBAAA0g5nZRU1Oz2l+KaXB3qQmxoY0OtwXdLPqxogeAND2ZmYXdfL0OS0sZ3Rjd0ILyxmdPH1OM7OLQTetbgQ9AKDtTU7PKRmPqaczpoiZejpjSsZjmpyeC7ppdSPoAQBtb34ppa5EdNO1rkRU80upgFq0dwh6AEDbG+xNajWd23RtNZ3TYG8yoBbtHYIeAND2JsaGlMpktbyWVd5dy2tZpTJZTYwNBd20uhH0AIC2NzrcpxNHj6i/J66LK2n198R14uiRUFTds70OAAAVwj4Mwb5VoCN6M/u0mb1sZt+q8vq4mV0ys68X33690W0EAKCVBT2i/2NJH5U0uc09X3H3o41pDgAA4RLoiN7dvyxpKcg2AAAQZq1QjDdmZv9gZp83s38WdGMAAGgl5u7BNsBsSNJpd/+BCq8dlJR39xUzu1fSR9z9cJWvc0zSMUkaGBh4y6lTp/ax1a1lZWVF3d3dQTejJdF39aH/6kP/7V679d0999xz1t1HKr3W1EFf4d45SSPuvrDdfSMjI37mzJm9aWAITE1NaXx8POhmtCT6rj70X33ov91rt74zs6pB39RT92b2WjOz4vt3qdDe1n/CAAAADRJo1b2Z/ZmkcUn9ZnZB0m9I6pAkd/+kpJ+U9PNmlpV0RdL9HvQUBAAALSTQoHf3d17n9Y+qsP0OAADsQlNP3QMAgPoQ9AAAhBhBDwBAiBH0AACEGEEPAECIEfQAAIQYQQ8AQIgF/ZhaAAD2xczsoian5zS/lNJgb1ITY0MaHe4LulkNx4geABA6q5mcTp4+p4XljG7sTmhhOaOTp89pZrb9TlEn6AEAobO4klYyHlNPZ0wRM/V0xpSMxzQ5PRd00xqOoAcAhE4mm1dXIrrpWlciqvmlVEAtCg5BDwAInXgsotV0btO11XROg73JgFoUHIIeABA6fd0JpTJZLa9llXfX8lpWqUxWE2NDQTet4Qh6AEDodMWjOnH0iPp74rq4klZ/T1wnjh5py6p7ttcBAEJpdLivLYN9K0b0AACEGEEPAECIEfQAAIQYQQ8AQIgR9AAAhBhBDwBAiBH0AACEGEEPAECIEfQAAIQYQQ8AQIgR9AAAhBhBDwBAiBH0AACEGEEPAECI8ZhaAEBLmJld1OT0nOaXUhrsTWpibIjH0NaAET0AoOnNzC7q5OlzWljO6MbuhBaWMzp5+pxmZheDblrTI+gBAE1vcnpOyXhMPZ0xRczU0xlTMh7T5PRc0E1regQ9AKDpzS+l1JWIbrrWlYhqfikVUItaR6BBb2afNrOXzexbVV43M/s9MztvZt8wszc3uo0AgOAN9ia1ms5turaazmmwNxlQi1pH0CP6P5b09m1ef4ekw8W3Y5I+0YA2AQCazMTYkFKZrJbXssq7a3ktq1Qmq4mxoaCb1vQCDXp3/7KkpW1uuU/SpBfMSDpkZjc3pnUAgGYxOtynE0ePqL8nrosrafX3xHXi6BGq7mvQ7NvrbpH0XNnHF4rXXgymOQCAoIwO9xHsu9DsQW8VrnnFG82OqTC9r4GBAU1NTe1js1rLysoK/bFL9F196L/60H+7R99d1exBf0HSbWUf3yrphUo3uvtDkh6SpJGRER8fH9/3xrWKqakp0R+7Q9/Vh/6rD/23e/TdVUEX413Po5ImitX3o5IuuTvT9gAA1CjQEb2Z/ZmkcUn9ZnZB0m9I6pAkd/+kpMck3SvpvKSUpHcH01IAAFpToEHv7u+8zusu6X0Nag4AAKHT7FP3AACgDgQ9AAAhRtADABBiBD0AACFG0AMAEGIEPQAAIUbQAwAQYjXtozezX7/OLS8XD7gBAKBmM7OLmpye0/xSSoO9SU2MDfHgmj1W64E5o5LuV+WHzEjSZyQR9ACAms3MLurk6XNKxmO6sTuhheWMTp4+x+Nn91itQZ9z98vVXjSzik+UAwCgmsnpOSXjMfV0FqKo9Ofk9BxBv4dqXaO/XpAT9ACAHZlfSqkrEd10rSsR1fxSKqAWhVOtI/oOMztY5TWTFK3yGgAAFQ32JrWwnNkYyUvSajqnwd5kgK0Kn1qDfkbS8W1e/3z9TQEAtJOJsSGdPH1OUmEkv5rOKZXJamLsjoBbFi472V5n27wBALAjo8N9OnH0iPp74rq4klZ/T5xCvH1Q64j+h0TVPQBgj40O9xHs+4yqewAAQoyqewAAQoyqewAAQoyqewAAQqzWoJeorgcAoOVQdQ8AQIhRdQ8AQIhRdQ8AQIhRdb8NnpMMAGh1VN1XUXpOcjbvWlxJa/biqr767IKOv/Ww3nP3cNDNAwCgJlTdVzE5Pads3vX8K1eUlyuby+tKxvXhx74tSYQ9AFTBbGhzoeq+ivmllBZX0srLtbael0mKmJTNu07+n2f0xae/p1962xv44QWAMqXZ0GQ8phu7E1pYzujk6XM8rCZAtRbj5dz9srtfqvSmEBbjDfYmtZrJaT2b3/jtJlf8W+Zd+trcKzo2eUaf/upsYG0EgGYzOT2nZDymns6YImbq6YwpGY9pcnou6Ka1Laruq5gYG1IsYlrPuSRXNr/5r5h3aXktqw8/9m3CHgCK5pdS6kpsrs/uSkQ1v5QKqEWoNeg7zOxglbcbFMKq+9HhPh1/62FFI6Z8hV9jtk7l//Qf/K1mZhcb3k4AaCaDvUmtpnObrq2mcxrsTQbUIuxF1b0phFX30tWCuwefeFar6ezG1L1U+EtXmsqnKh9AO5sYG9LJ0+ckFUbyq+mcUpmsJsbuCLhl7YtivOt4z93DOvK6G/S7j39HX5tbUt4L0yD5Cvem0lkK9QC0tdHhPp04emRL1f0d/HsYII7ArcHocJ/+938a06e/OqsPP/Zt5d03VSWYCqN6GaN7ABgd7iPYm0igxXhm9nYz+0czO29mH6jw+riZXTKzrxfffn0332evvOfuYf3qvW9UdyKmaHFuo9SBG2EvCvUAAM0jsCNwzSwq6WOS3ibpgqSvmdmj7n5uy61fcfejO/36+2XrVH7E7JqKfJMUjUh5dz34xLM68rob+O0WABCInRbjVVuj/8Iuvvddks67+6wkmdkpSfdJ2hr0Tad8Kr9SoV7EJPfC2/JaVsdPPaUH738TYQ8AaLiagt7d//s+fO9bJD1X9vEFFYr+thozs3+Q9IKk/+LuT+9DW3alWqGedLUi3yS9dDnNmj0AIBDmHkwdnZn9lKR/4+7/sfjxuyTd5e7vL7vnoKS8u6+Y2b2SPuLuh6t8vWOSjknSwMDAW06dOrXvf4dyiysZvXhpTZJfU7BgMpXKGJKJmAYOdqor3rijB1ZWVtTd3d2w7xcm9F196L/60H+71259d88995x195FKr+3koTZ77YKk28o+vlWFUfuG8kp/d3/MzD5uZv3uvrD1i7n7Q5IekqSRkREfHx/fl0ZvpzSVv7yW3bhmxWl8K1bkR0zqTmR1/K23N2x0PzU1pSD6Iwzou/rQf/Wh/3aPvruq1qr7/fA1SYfN7HYzi6uwT//R8hvM7LVmZsX371KhvU17/Nx77h7WQxMjGjiYkCR1RAtj+UjkakV+KfgffOJZTtIDAOy7wILe3bOSfkHSFyU9I+mz7v60mb3XzN5bvO0nJX2ruEb/e5Lu96DWGmo0OtynB+9/k3o6Y0rEonJJueLpOhEVpvHX1nMbRXqEPQBgPwU5dS93f0zSY1uufbLs/Y9K+mij21Wv0jn5Dz7x7MY2hYgkmZTLuyJW2H53cTmtn/ujv9cP3noDJ+kBaHo8Z741BTl1H2qlafyRoV5FTIpETFZco3dJ2bwkk7K5PI+8BdD0Ss+ZX1jObHrOPLOSzY+g30el/fYnfvxOJeNR5SVFrJD0ZlI+f7VQj3V7AM2M58y3LoK+AcqL9DpiEUUipoikaMRkxro9gObHc+ZbF0HfIKUiveH+Lh3sjBWr8F15L6zb54o1hqXDdZjGB9BMeM586yLoG6j0+MbDAz0qbhqUle2xlwqj/NLjbn/6D/6W0T2ApjAxNqRUJqvltazy7lpeyxafMz8UdNNwHQR9g1Vat3cvHJVrxar80v7B77y0QrELgKZQGqj098R1cSWt/p64Thw9QtV9Cwh0e107K52Tf/zUU3rpclodUStsvYsUjss1FR6IM7uwykNxADQFnjPfmhjRB6jS4Tqldftsvvi4W7u6356pfADAThH0ASsdrlOovpekwva7qEmxqGk1k1PETIlYhKl8AMCOEfRNoPxwnVi0kPgHOqJazxWm8GNRUyqd06Ur63rh1Sv63ce/E3STAQAtgqBvEqUivT9+9126qSeh4vH4isciyuRceXdFzHT5yrr+/rtLTOMDAGpC0DeZrfvt17OF4/MKD8cp/BmNGNP4AICaEPRNqHy/fc4ls6vn5EumjsjminzCHgBQDUHfpEpT+Xfd/hr1dMbkVhjJx2OmdHHtnop8AMD1EPRN7pfe9gbdcuiADh3ouKZAj4p8AHthZnZRDzx8Vkd//yt64OGz/DsSMgR9kyufxk/n8sq7bwr8Ax0R5fPOVD6AXeHxs+FH0LeAahX5yXhUssLI3iR1xiK6vJblf1IANePxs+FH0LeQrRX5ETOliiF/oCOidDavXN4Z2QOoGY+fDT+CvsVUm8rPuXRlPadYxK4p0lvN5K7/hQG0JR4/G34EfQuqNJWfzRcCPxq5tkjvxVevMLoHUBGPnw0/gr6FlU/lRyOFYC+fyi8V6aWzeabyAVTE42fDj8fUtrjS/6THTz2ly2tZSWVFeumsomaKmDaK9PgfGMBWPH423BjRh8D1ivTyLor0AKBNEfQhsV2RnrsrFjG23wFAGyLoQ6RakZ6Z6UBHlO13ANCGCPoQ2lqkF7HC1rtq2+8IfAAIL4I+pEpT+Qc7Y8r79tvvmMoHgPAi6EOsNLJPxCLbbr9jKh8IJx5WA4mgD73R4T7dfOiADnbGtJYtnJLPGflA+PGwGpQQ9G2gKx7ljHygzfCwGpQQ9G2iljPyGdkD4cHDalBC0LeR7c7IP9ARVd5d8WhEL7x6Rccmz7CmB7QwHlaDEoK+DVU6Iz+bzyuddaXXc8rlXe7Omh7QwnhYDUoI+jZVvv1uLZtXPBpVPGZKdERlJkUjEc0trrJuD7QoHlaDkkAfamNmb5f0EUlRSZ9y99/c8roVX79XUkrSz7n7kw1vaEiVRvYnT59TMh7TuRcvKRqRMlmXvFChX75uzz8SQGvhYTWQAhzRm1lU0sckvUPSEUnvNLMjW257h6TDxbdjkj7R0Ea2gfLf+iNmiphtjOxjEaMiHwBaXJBT93dJOu/us+6ekXRK0n1b7rlP0qQXzEg6ZGY3N7qhYTc63KeP/8xb9NDEiG45dEDrOb/m2Fwq8gGgNQU5dX+LpOfKPr4g6YdquOcWSS9u/WJmdkyFUb8GBgY0NTW1l21taSsrKzX3x8+/MafnltaVy/vGtYjl5Sp8bMroyb/7v/rO12Pq606oKx6t9qVCYSd9h2vRf/Wh/3aPvrsqyKC3Ctd8F/cULro/JOkhSRoZGfHx8fG6GhcmU1NT2kl/lE7Uml1YVWcsory70lmX3BUvfnznzTcodSEb+nX7nfYdNqP/6rNd/83MLmpyek7zSykN9iY1MTYU6v8Xd4qfvauCnLq/IOm2so9vlfTCLu7BHqMiH2huHG+LnQgy6L8m6bCZ3W5mcUn3S3p0yz2PSpqwglFJl9z9mml77L3yvfZD/V2FvfXyjb32mWyedXsgIBxvi50ILOjdPSvpFyR9UdIzkj7r7k+b2XvN7L3F2x6TNCvpvKT/JemBQBrbpq5Xkc9JekAwON4WOxHoPnp3f0yFMC+/9smy913S+xrdLlxV2oe7ed3eNk7Sk+cVj0U2naQX9nV7IGiDvUktLGfU03n1n3COt0U1nIyHmrBuDzQPjrfFThD0qBnr9kBz4Hhb7ESgU/doPaV/YCan5xT5XmndXjJFFIsUpvTL1+3vPtzPth9gH3C8LWrFiB47Vu0kPZ6ABwDNh6DHrrFuDwDNj6BHXVi3B/bezOyiHnj4rM6/vMK2VdSNoEfd2G8P7J3yU+9i0QjLX6gbQY89wbo9sDfKT70ziVPvUDeCHnvqeuv2BzpiyubzjO6BKjj1DnuNoMeeq7Zun8tLNxyI6dmXVhjdA1UM9ia1ms5tusapd6gHQY99UWnd/vU3denSWlbRiFGVD1RRfuqdS5x6h7oR9Ng3W9ftO6JRpTJZqvKBbZT/kpzN5Tn1DnUj6LHvaqnK745TcASUlH5Jfv1N3fr4z7yFkEddOAIXDbHdU/ByeemG7pi+u7Cibzyf1QMPn+XYXITazOyiJqfnNL+U0mBvkp937CtG9GioSlX5rz2Y0Pcup7W2nldPIkaBHkKtfJ/8jd0Jft6x7wh6NNzWqvxXr6xvvHbraw6w/Q6hVr5PPmLGPnnsO4IegShft19OZ9XZEdHrb+qSmbH9DqHGPnk0GkGPwJQKjv71G2/S7f3d6u1K6MIrVza233G4DsKIffJoNIIegSvfN1zafsfhOgir8p/3vDv75LHvCHoErpbDdRjdIyzKf94vrqTZJ499x/Y6NIWt2+9Kh+tEI6Z8cfvdsy+tKGLaNLrnH0i0otLPO9AIBD2aSmm0Mzk9p8j3CqP74ZuSev7VNUUjJsl1ILZ5dH/34X72IaOpsE8ezYSpezSd7Y7OZe0ezY598mg2BD2aVq1r9+xDRjNhnzyaDUGPpna90f0tr+nUK6mMvruwor/+9ssU6SFw7JNHsyHo0RKqje5LB+xwfC6aBfvk0WwoxkPLqFSZ/92FlY3Xb33NAfV0xnR5bV3HTz2l/p4EhVBouImxIZ08fU5SYSS/ms4V98nfEXDL0K4Y0aPlVDs+t7croVdSGV1YSunyWpZCKOybmdlFPfDwWR39/a9cs1zEPnk0G0b0aEml0f0DD5/VwnJGPZ2FH+ULr1yRmam7I6qIGdvwsOdKM0rJeGzTL5PlYc4+eTQTRvRoaVuPE11JFwr1SkV6bMPDXqOqHq2GoEdL2zpNerAzplsPHeABOdg3VNWj1TB1j5ZXPk1amlYtPSiEI3Sx1wZ7k5uWiySq6tHcGNEjVHZyyE427zp+6qmKBVVANTx9Dq0mkKA3s14ze9zMni3++Zoq982Z2TfN7OtmdqbR7URrqvWQHarzUQ1V9QiToKbuPyDpr9z9N83sA8WPf6XKvfe4+0LjmoawqPaAnN6uhL75/CWq81ERVfUIm6Cm7u+T9Jni+5+R9G8DagdCrtLonup8bIeqeoRNUEE/4O4vSlLxz5uq3OeSvmRmZ83sWMNah9DZSXV++fr9+ZdXWL9vM1TVI2zM3ffnC5s9Iem1FV76NUmfcfdDZfe+4u7XrNOb2evc/QUzu0nS45Le7+5frvL9jkk6JkkDAwNvOXXq1B78LcJhZWVF3d3dQTejqaxmcnrx1SuKmGltPScVHnWvREdEkim9npNLem1SurRemAW4+dABdcWj1/nKKNeKP3vzSyllc65oxDau5fKuWNQaXlnfiv3XLNqt7+65556z7j5S6bV9C/rtmNk/Shp39xfN7GZJU+7+hut8zockrbj7b13v64+MjPiZM9TulUxNTWl8fDzoZjSdmdlFTU7P6avPLigaMQ31XV2/v5LJ6UBHVO+7M6MvL9+o51+9oldTGc7P36Fm/tkr/fefX0pt+m9avkZfflZ9EAV3zdx/za7d+s7MqgZ9UFP3j0r62eL7PyvpL7feYGZdZtZTel/Sj0n6VsNaiNCrZf1eEhX6IVQK84XlzDX/TamqR9gEVXX/m5I+a2b/QdK8pJ+SClP1kj7l7vdKGpD0F2ZWauefuvsXAmovQqy8On9+KaWDnTEdOtCh3q6EJM7PD6PygjtJG39OTs9tVNTz3xRhEUjQu/uipB+tcP0FSfcW35+V9IMNbhraVLXT9bxHWklnFTFtqtDnhL3WNr+U0o3diU3XKLhDWHEELrBF+Qg/m8vrYGd8Y4T/zecvFYu0XAdihRHh5bV1HT/1FOv3TajaOjzH2KKdcAQuUEFp/f71N3XrwfvfpFg0snHUKSfstYbt1uE5xhbthKAHrqPa+fmlPfhmpu741cNVOEO/OWx38A0Fd2gnTN0DNSit4ZdGieUV+qX1e+lqhX5e0p03H2QNvwGqTc9fbx2egju0C0b0wA5sd8KeJEb4Dbbd9Pxgb1Kr6dym+1mHRzsi6IEdKq3fn37/v9q0fs8e/MbbbnqedXiggKl7oA473YNPlf7uVZqi3256fut/m8Ln3EFfo+0Q9ECdqu3B70pEa17D/3dvvkVn/umVa9aZUVDt0bGlI2qrbZNjHR4g6IE9tdsR/oNPPKs3vvbgRoh98JFv6KaehFYzOYJf1U+yk6RUJitJm86lnxi7I5B2As2IoAf22E5G+JK0uJJWNu8b4ZXN5/XSpbReTa3rX952qO0q93cyRX9xJc30PHAdBD2wj643wpcKj8wtf/zthVeuqCNqyuY8tOv6tTw5rtYpeqbnge0R9MA+226Ev5rOKRYx9XXFN+6/sp5TxKQDsUL4h21dv1qYl34hYooe2FsEPdBAlSrBj//AYT3y5PMb4d8RMa1l8xruL0zv17qu34zhv5rJ6YGHz25qz3ZPjmOKHth7BD3QYJWmmo+87oaNEDs80KOXLl2pevqedO26/k6K+iRVnTbfer3SvbV+/sj3vUb5V69oYTm56ZeRlfS6bu/v3vT3L22J2+5hM0zRA7tD0ANNYGuIlYdmLev6Um1FfR985BvyvOumgweumQl45MnnN02nV7p3J5//4BPP6v1HdM3IfWElXXW9fWJsSCdPn5PEFD2wVwh6oAntdF1fqq2o7/zL63JJ33/T5vB96MuzGuzt2hTKle7dyedn865szje1sSsR1YF4rOp6O4fcAHuPoAeaXC3r+rUU9UlSJpeXbfn6XYmoXr2yrjsTm2cIKt27k8/vikeV98yma6vpnO68uWdjrb5SmDNFD+wtgh5oAddb16+lqE+S4tGIfMvXXk3ndOhAxzXT6ZXu3cnn93UnZHZl0y8j5SN3whxoDIIeaFE7LepbTed0Q7JDnvdrwvfYjwzrkSefl3R1Or3SvTv5/FjENNDTqf58nGl4IEAEPRAi2xX1DfYm9Z9/rFDUVmnafOsMQaV7d/L5E2N3aG3+m/r40bc0viMAbCDogRCrNkVe7dpO7q3l86fmd9JaAPuB59EDABBiBD0AACFG0AMAEGIEPQAAIUbQAwAQYgQ9AAAhRtADABBiBD0AACFm7ltPrm59ZnZR0j8F3Y4m0i9pIehGtCj6rj70X33ov91rt777Pne/sdILoQx6bGZmZ9x9JOh2tCL6rj70X33ov92j765i6h4AgBAj6AEACDGCvj08FHQDWhh9Vx/6rz703+7Rd0Ws0QMAEGKM6AEACDGCvg2Y2f80s2+b2TfM7C/M7FDQbWoFZvZ2M/tHMztvZh8Iuj2twsxuM7O/MbNnzOxpM/vFoNvUiswsamZPmdnpoNvSaszskJl9rvjv3jNmNhZ0m4JE0LeHxyX9gLv/C0nfkfTBgNvT9MwsKuljkt4h6Yikd5rZkWBb1TKykn7Z3e+UNCrpffTdrvyipGeCbkSL+oikL7j7GyX9oNq8Hwn6NuDuX3L3bPHDGUm3BtmeFnGXpPPuPuvuGUmnJN0XcJtagru/6O5PFt9fVuEf2VuCbVVrMbNbJf24pE8F3ZZWY2YHJf2IpD+UJHfPuPurgTYqYAR9+3mPpM8H3YgWcIuk58o+viDCasfMbEjSmyT9XcBNaTUPSvpvkvIBt6MVDUu6KOmPiksfnzKzrqAbFSSCPiTM7Akz+1aFt/vK7vk1FaZVHw6upS3DKlxji8oOmFm3pD+XdNzdLwfdnlZhZkclvezuZ4NuS4uKSXqzpE+4+5skrUpq6xqbWNANwN5w97du97qZ/ayko5J+1NlTWYsLkm4r+/hWSS8E1JaWY2YdKoT8w+7+SNDtaTE/LOknzOxeSZ2SDprZn7j7vw+4Xa3igqQL7l6aRfqc2jzoGdG3ATN7u6RfkfQT7p4Kuj0t4muSDpvZ7WYWl3S/pEcDblNLMDNTYX30GXf/naDb02rc/YPufqu7D6nwc/fXhHzt3P17kp4zszcUL/2opHMBNilwjOjbw0clJSQ9Xvg3WDPu/t5gm9Tc3D1rZr8g6YuSopI+7e5PB9ysVvHDkt4l6Ztm9vXitV9198eCaxLazPslPVz8JX1W0rsDbk+gOBkPAIAQY+oeAIAQI+gBAAgxgh4AgBAj6AEACDGCHgCAECPoAQAIMYIeAIAQ48AcAJuY2YdUeLxs6YmHMRWeeljpmvbiurt/aC//DgCuIugBVHJ/6dGeZnZI0vEq16rdu5vrAPYBU/cAAIQYQQ8AQIgR9AAAhBhBDwBAiBH0AACEGEEPAECIsb0OwFYvS5o0s3zx44ikL1S5pj28DmAfmLsH3QYAALBPmLoHACDECHoAAEKMoAcAIMQIegAAQoygBwAgxP4/7hKTYNuOMp4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# GPU  CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# \n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # \n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST \n",
    "])\n",
    "\n",
    "#  MNIST \n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)      # \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# \n",
    "model = MLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # \n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# \n",
    "param_history = []\n",
    "\n",
    "# \n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # \n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # \n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    #  epoch \n",
    "    params = torch.cat([p.view(-1).detach().cpu() for p in model.parameters()])\n",
    "    param_history.append(params.numpy())\n",
    "\n",
    "# \n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# \n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "# \n",
    "param_history = np.array(param_history)\n",
    "\n",
    "#  PCA \n",
    "pca = PCA()\n",
    "pca.fit(param_history)\n",
    "\n",
    "# \n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(\":\", explained_variance_ratio[:10])\n",
    "\n",
    "# \n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(cumulative_variance, marker='o')\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# \n",
    "principal_components = pca.transform(param_history)\n",
    "pc1 = principal_components[:, 0]\n",
    "pc2 = principal_components[:, 1]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(pc1, pc2, alpha=0.7)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
